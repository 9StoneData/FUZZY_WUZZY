{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9StoneData/FUZZY_WUZZY/blob/main/DISP_2_MAN_MAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_dXdQtmM_Qp"
      },
      "outputs": [],
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install fuzzywuzzy\n",
        "!pip install num2words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w6zWFJKZNlJL"
      },
      "outputs": [],
      "source": [
        "global CORES\n",
        "import multiprocessing\n",
        "CORES=multiprocessing.cpu_count()\n",
        "import re\n",
        "\n",
        "from num2words import num2words\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "import concurrent.futures\n",
        "import datetime as dt\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import gc\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "from fuzzywuzzy import process,fuzz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHrgJ1srm1IO"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "When collecting data from Leafly.com, products are listed in two places.  First, they are listed as offferings from dispensaries.  Second, they are listed under the product section categorized by type and sub category.  \n",
        "\n",
        "Dispensaries advertise the same product from the same manufacturer with different variations of the manufacturere and product name, and or they add additional information to the names, i.e. product size, flavor, price, or promotions.  \n",
        "\n",
        "An additional issue is that under the product section, not all of the manufacturers and their respective product catelogs are listed.\n",
        "\n",
        "If one is to analize products from Leafly, one must homogenize thier names.  In other spaces such as the Automotive Retail Space or Grocery Space, products have either a VIN or a UPC allowing one to analyize or group identicle products.  Leafly does not have this.  \n",
        "\n",
        "The output from the despencary product level is non homeginzed preventing accurate analysis of the products.  \n",
        "\n",
        "#Solution\n",
        "\n",
        "Utlizing the fuzzy library with the Levenshtein algorithim  and various data cleansing techniques, develop a homogenized list of products and manufacturer names. \n",
        "\n",
        "The list of products at dispensaries is gathered at the State Market Level.  For Arizone, there are over 90k products advertised.  From the product page scrape, there are over 60k different products.  Multi thread processing will be required to effeciently process and map the Manufacturer and Product names so one can have confidence in their analyis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKydDSvkmV9G"
      },
      "source": [
        "## Part 1.1: Read in Products from Leafly.com product scrape:  \n",
        "\n",
        "These are catorgized by product category and will serve as the main name for Manufacturer and Product.  Check to see if there are variations in the Manufacturer name to ensure homogenized and clean data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9WZnJ0cmVgP"
      },
      "outputs": [],
      "source": [
        "MAN_PROD=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Run_Results/9Stone/_PROD_PAGE_DETAILS_.csv\")\n",
        "MAN_PROD.info()\n",
        "MAN_PROD.loc[MAN_PROD['Manufacturer'].isna(),'Manufacturer']=\"DO NOT KNOW FOR SURE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_KjWmVEsTJA"
      },
      "source": [
        "## Part 1.2: Keep columns of interest:  \n",
        "\n",
        "Columns of interest:\n",
        "\n",
        "*   pdv          : product detail page url\n",
        "*   True_Product : Name of product\n",
        "*   Manufacturer : Name of Manufacturer\n",
        "*   category     : Main product category (Cannabis, Edibles,Vapes, etc)\n",
        "*   sub-category : preroll, sublingual, cookies, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74sjzjQatTCP"
      },
      "outputs": [],
      "source": [
        "MAN_PROD=MAN_PROD[['Manufacturer','True_Product','category','sub-category','pdv']]\n",
        "MAN_PROD.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eltpiujuA_w"
      },
      "source": [
        "## Part 2.1: Check for duplicate manufacturers:  \n",
        "\n",
        "Make sure the same manufacturer is not listed multiple times with slight variaotiosn to their name, i.e. LOVELY and LOVELI and LOVELY inc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VEI4_pLYue_S"
      },
      "outputs": [],
      "source": [
        "\n",
        "#list of manufacturers\n",
        "mans=list(set(MAN_PROD['Manufacturer']))\n",
        "\n",
        "#DF lookup table for competing names\n",
        "VC=pd.DataFrame(MAN_PROD['Manufacturer'].value_counts())\n",
        "\n",
        "#depending on cpu use, Process pool or Thread pool will be used for asynchronous processing\n",
        "#keep in mind that a=b in one thread, b=a in another or in a different search.  resolve this\n",
        "# by picking the one with more products as the master name.  will require manual review of changes\n",
        "# but, can autmate the process with screen input once out of the step\n",
        "\n",
        "\n",
        "#Prepair data for asynchrounous processing\n",
        "THREADS=CORES\n",
        "\n",
        "query  = mans.copy()\n",
        "search = mans.copy()\n",
        "\n",
        "QUERY  = pd.DataFrame(query ,columns=['Manufacturer'])\n",
        "SEARCH = pd.DataFrame(search,columns=['Manufacturer'])\n",
        "\n",
        "#configure \n",
        "QUERY['THREAD']=QUERY.index%THREADS\n",
        "MASTER_LIST=[]\n",
        "for i in range(THREADS):\n",
        "  temp  = []\n",
        "  tdf   = QUERY[QUERY['THREAD']==i]\n",
        "  #send copies not pointers to original\n",
        "  tdf   = tdf.copy()\n",
        "  #easier to reference rows\n",
        "  tdf.reset_index(inplace=True)\n",
        "  tdf.drop(['index'],axis=1,inplace=True)\n",
        "  tdf['query_column'] = 'Manufacturer'\n",
        "  tdf['query_name']=\"product_manufacturer_vs_product_manufacturer_.csv\"\n",
        "  tdf['directory'] = \"/content/drive/MyDrive/LEAFLY_Project/Data/THREAD_RESULTS/MAPPING\"\n",
        "  tdf['Multiple_Possible_Names']=False\n",
        "  tdf['MASTER_MAN_NAME']=tdf['Manufacturer']\n",
        "  tdf['algo_step']=1\n",
        "  SEARCH = SEARCH.copy()\n",
        "  SEARCH['search_column']='Manufacturer'\n",
        "  temp.append(tdf)\n",
        "  temp.append(SEARCH)\n",
        "  VC=VC.copy()\n",
        "  temp.append(VC)\n",
        "  MASTER_LIST.append(temp)\n",
        "\n",
        "def process_for_match(LIST_o_DF):\n",
        "\n",
        "  try:\n",
        "\n",
        "    QUERY_DF          = LIST_o_DF[0]\n",
        "    q1_LIST_column    = QUERY_DF.at[0,'query_column']\n",
        "    q1_LIST           = list(QUERY_DF[q1_LIST_column]) \n",
        "\n",
        "    SEARCH_DF         = LIST_o_DF[1]\n",
        "    s1_LIST_coliumn   = SEARCH.at[0,'search_column']\n",
        "    s1_LIST           = list(set(SEARCH_DF[s1_LIST_coliumn]))\n",
        "\n",
        "    VC                = LIST_o_DF[2]\n",
        "  except:\n",
        "    print(\"error initializing dfs\")\n",
        "\n",
        "  try:\n",
        "    if QUERY_DF.at[0,'algo_step']==1:\n",
        "      for q,query in enumerate(q1_LIST):\n",
        "        \n",
        "        try:\n",
        "          ops=process.extract(query,s1_LIST)\n",
        "        except:\n",
        "          print(\"oops error\",query)\n",
        "\n",
        "        master=query\n",
        "     \n",
        "        if len(ops)>0:\n",
        "          \n",
        "          for o,op in enumerate(ops):\n",
        "            EXACT=False\n",
        "            #assuming forst one is the same, but can check\n",
        "            if query==op[0]:\n",
        "              EXACT=True\n",
        "        \n",
        "            #ran various thresholds.  92 + is least number of false positives\n",
        "            if not EXACT and  op[1]>=92:\n",
        "              #Decide on master name by which one hsows up more \n",
        "              man1=query\n",
        "              man2=op[0]\n",
        "    \n",
        "              if VC.at[man2,'Manufacturer'] > VC.at[man1,'Manufacturer']:\n",
        "                master=man2\n",
        "              print(f\"{q:3} {query:40} =?= {op[0]:40} {VC.at[man1,'Manufacturer']:5} {VC.at[man2,'Manufacturer']:5} {master}\")\n",
        "              QUERY_DF.at[q,'Multiple_Possible_Names']=True\n",
        "              QUERY_DF.at[q,f\"_{o}_possible_name\"]=op[0]\n",
        "              QUERY_DF.at[q,\"Number_of_Possible_Names\"]=o\n",
        "              QUERY_DF.at[q,'MASTER_MAN_NAME']=master\n",
        "              \n",
        "              \n",
        "        \n",
        "        # if q%10==0:\n",
        "        #   print(ops)\n",
        "      #by design, as the DF's are returned, the master df is rebuilt\n",
        "  except:\n",
        "    print(\"Error getting ops\")\n",
        "\n",
        "\n",
        "  return(QUERY_DF,SEARCH_DF)\n",
        "\n",
        "def process_for_match_THREADED(MASTER_LIST):\n",
        "  threads=len(MASTER_LIST)\n",
        "\n",
        "  FDF=pd.DataFrame()\n",
        "  FMMDF=pd.DataFrame()\n",
        "\n",
        "  with concurrent.futures.ProcessPoolExecutor(max_workers=threads) as executor:\n",
        "    try:\n",
        "        for r,results in enumerate(executor.map(process_for_match,MASTER_LIST)):\n",
        "          FDF=FDF.append(results[0],ignore_index=True)\n",
        "        \n",
        "        path=FDF.at[0,'directory']\n",
        "        file_name=FDF.at[0,'query_name']\n",
        "        file_date_stamp=dt.datetime.now()\n",
        "        file_date_stamp=file_date_stamp.strftime(\"%m_%d_%Y_%H_%M_\")\n",
        "        FDF.to_csv(join(path,f\"_{file_name}\"),index=False)\n",
        "        FDF.to_csv(join(path,f\"_{file_date_stamp}_{file_name}\"),index=False)\n",
        "        print(FDF.info())\n",
        "\n",
        "    except:\n",
        "        print(\"OOPS\")\n",
        "\n",
        "  return FDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9XOKoad_ZAy"
      },
      "outputs": [],
      "source": [
        "FDF=process_for_match_THREADED(MASTER_LIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAjkPekJX0Js"
      },
      "source": [
        "## Part 2.2: Overwrite manufacturer names with Master Name, and remove uncessary columns\n",
        "\n",
        "Resulting columnns:\n",
        "* 'Manufacturer'             : original name\n",
        "* *'THREAD'*\n",
        "* *'query_column'* \n",
        "* *'query_name'* \n",
        "* *'directory'*\n",
        "* *'Multiple_Possible_Names' * \n",
        "* 'MASTER_MAN_NAME'          : Name to use for all matchtes\n",
        "* '_1_possible_name' \n",
        "* 'Number_of_Possible_Names' \n",
        "* '_0_possible_name' \n",
        "* '_2_possible_name'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYrE5YOwYEgq",
        "outputId": "3498f5f9-46ee-49b2-97c6-5db74b5cf9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of unique Manufactureres___________: 3077\n",
            " Manufacturers to correct__________________:   27\n",
            " Products with Manufacturer name adjusted__:  141 of 141 with 0 missed\n"
          ]
        }
      ],
      "source": [
        "#Original Product Scrped Table = MAN_PROD\n",
        "#reloading for the sake of not having to scroll back to top to run again\n",
        "MAN_PROD=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Run_Results/9Stone/_PROD_PAGE_DETAILS_.csv\")\n",
        "\n",
        "FDFa = FDF[['Manufacturer','MASTER_MAN_NAME','Number_of_Possible_Names']]\n",
        "print(f\" Number of unique Manufactureres___________: {FDFa.shape[0]:4}\")\n",
        "#FDFa=FDFa.drop_duplicates(subset=['MASTER_MAN_NAME'],keep='first')\n",
        "\n",
        "temp = FDFa[FDFa['Manufacturer']!=FDFa['MASTER_MAN_NAME']]\n",
        "print(f\" Manufacturers to correct__________________: {temp.shape[0]:4}\")\n",
        "\n",
        "\n",
        "tofix=0\n",
        "for man in list(temp['Manufacturer']):\n",
        "  test=MAN_PROD[MAN_PROD['Manufacturer']==man]\n",
        "  tofix+=len(test)\n",
        "\n",
        "corrections=0\n",
        "for man in list(temp['Manufacturer']):\n",
        "  tdf=(MAN_PROD.loc[MAN_PROD['Manufacturer']==man,'Manufacturer'])\n",
        "  corrections+=len(tdf)\n",
        "  MAN_PROD.loc[MAN_PROD['Manufacturer']==man,'Manufacturer']=temp.loc[temp['Manufacturer']==man,'MASTER_MAN_NAME']\n",
        "  #tdf=(MAN_PROD.loc[MAN_PROD['Manufacturer']==man,'Manufacturer'])\n",
        "  # print(f\"{man} :: {len(tdf)} :: {temp.loc[temp['Manufacturer']==man,'MASTER_MAN_NAME']} ::::::::\")\n",
        "  #print(f\"{temp.loc[temp['Manufacturer']==man,'MASTER_MAN_NAME']} ::::::::\")\n",
        "\n",
        "errors=0\n",
        "for man in list(temp['Manufacturer']):\n",
        "  test=MAN_PROD[MAN_PROD['Manufacturer']==man]\n",
        "  if len(test)>0:\n",
        "    print(man)\n",
        "  errors+=len(test)\n",
        "print(f\" Products with Manufacturer name adjusted__: {corrections:4} of {tofix} with {errors} missed\")\n",
        "\n",
        "MAN_PROD.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/MASTER_PRODUCT_LSIT_renamed_mans.csv\",index=False)\n",
        "FDFa.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/MASTER_PRODUCT_LSIT_keys.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_JgJ5SRkLsH"
      },
      "source": [
        "## Part 3.1: Start Mapping Dispensary products manufactureres to Master List\n",
        "\n",
        "Scrapes generate a csv of Dispensary Catelog of products.  Most have a manufacturer listed.  \n",
        "\n",
        "Need to build a table to map them to Master Manufacturer List.  Very similar process as step 2, just need to reconfigure MASTER_LIST\n",
        "\n",
        "Scraper runs 1 to many State Markets a day based on time constraints and inputs.  Each state will have to be initially processed to build mapping table, and updated from time to time based ona schedule\n",
        "\n",
        "first step is to homeginze the disp manf names to itself "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmBaInGnkbpG"
      },
      "outputs": [],
      "source": [
        "SDF =pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Run_Results/9Stone/_AZ_Market_Data_.csv\")\n",
        "MAN_PROD=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/MASTER_PRODUCT_LSIT_renamed_mans.csv\")\n",
        "\n",
        "print(SDF.shape)\n",
        "SDF.loc[SDF['Manufacturer'].isna(),'Manufacturer']=\"TBD9999999999999999999999999999888888888888888888888888888888\"\n",
        "SDF.loc[SDF['Manufacturer']==\"-\",'Manufacturer']=\"TBD99999999999999999999999999999999999999999999999999\"\n",
        "#list of manufacturers\n",
        "disp_mans=list(set(SDF['Manufacturer']))\n",
        "mans=list(set(SDF['Manufacturer']))\n",
        "\n",
        "\n",
        "#DF lookup table for competing names\n",
        "VC=pd.DataFrame(SDF['Manufacturer'].value_counts())\n",
        "\n",
        "#depending on cpu use, Process pool or Thread pool will be used for asynchronous processing\n",
        "#keep in mind that a=b in one thread, b=a in another or in a different search.  resolve this\n",
        "# by picking the one with more products as the master name.  will require manual review of changes\n",
        "# but, can autmate the process with screen input once out of the step\n",
        "\n",
        "\n",
        "#Prepair data for asynchrounous processing\n",
        "THREADS=CORES\n",
        "\n",
        "query  = disp_mans.copy()\n",
        "search = mans.copy()\n",
        "\n",
        "QUERY  = pd.DataFrame(query ,columns=['Manufacturer'])\n",
        "SEARCH = pd.DataFrame(search,columns=['Manufacturer'])\n",
        "\n",
        "#configure \n",
        "QUERY['THREAD']=QUERY.index%THREADS\n",
        "MASTER_LIST=[]\n",
        "for i in range(THREADS):\n",
        "  temp  = []\n",
        "  tdf   = QUERY[QUERY['THREAD']==i]\n",
        "  #send copies not pointers to original\n",
        "  tdf   = tdf.copy()\n",
        "  #easier to reference rows\n",
        "  tdf.reset_index(inplace=True)\n",
        "  tdf.drop(['index'],axis=1,inplace=True)\n",
        "  tdf['query_column'] = 'Manufacturer'\n",
        "  tdf['query_name']=\"product_manufacturer_vs_vendor_manufacturer_.csv\"\n",
        "  tdf['directory'] = \"/content/drive/MyDrive/LEAFLY_Project/Data/THREAD_RESULTS/MAPPING\"\n",
        "  tdf['Multiple_Possible_Names']=False\n",
        "  tdf['MASTER_MAN_NAME']=tdf['Manufacturer']\n",
        "  tdf['algo_step']=1\n",
        "  SEARCH = SEARCH.copy()\n",
        "  SEARCH['search_column']='Manufacturer'\n",
        "  temp.append(tdf)\n",
        " \n",
        "  temp.append(SEARCH)\n",
        "  VC=VC.copy()\n",
        "  temp.append(VC)\n",
        "  MASTER_LIST.append(temp)\n",
        "\n",
        "\n",
        "FDF=process_for_match_THREADED(MASTER_LIST)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ-lXCTpJKJS"
      },
      "source": [
        "# Step 3.2: Now Overwrite scraped names in Dispensary Product results\n",
        "\n",
        "THIS CELL SHOULD BE a function to call for both of the similar steps..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj9-x27NJJKz",
        "outputId": "0e58d2e9-d4ba-40d6-e725-755b27e025f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of unique Manufactureres___________:  961\n",
            " Manufacturers to correct__________________:  146\n",
            " Products with Manufacturer name adjusted__: 1281 of 1281 with 0 missed\n"
          ]
        }
      ],
      "source": [
        "#Original Product Scrped Table = MAN_PROD\n",
        "#reloading for the sake of not having to scroll back to top to run again\n",
        "#MAN_PROD=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Run_Results/9Stone/_PROD_PAGE_DETAILS_.csv\")\n",
        "SDF =pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Run_Results/9Stone/_AZ_Market_Data_.csv\")\n",
        "FDFa = FDF[['Manufacturer','MASTER_MAN_NAME','Number_of_Possible_Names']]\n",
        "print(f\" Number of unique Manufactureres___________: {FDFa.shape[0]:4}\")\n",
        "#FDFa=FDFa.drop_duplicates(subset=['MASTER_MAN_NAME'],keep='first')\n",
        "\n",
        "temp = FDFa[FDFa['Manufacturer']!=FDFa['MASTER_MAN_NAME']]\n",
        "print(f\" Manufacturers to correct__________________: {temp.shape[0]:4}\")\n",
        "\n",
        "\n",
        "tofix=0\n",
        "for man in list(temp['Manufacturer']):\n",
        "  test=SDF[SDF['Manufacturer']==man]\n",
        "  tofix+=len(test)\n",
        "\n",
        "corrections=0\n",
        "for man in list(temp['Manufacturer']):\n",
        "  tdf=(SDF.loc[SDF['Manufacturer']==man,'Manufacturer'])\n",
        "  corrections+=len(tdf)\n",
        "  SDF.loc[SDF['Manufacturer']==man,'Manufacturer']=temp.loc[temp['Manufacturer']==man,'MASTER_MAN_NAME']\n",
        "  #tdf=(MAN_PROD.loc[MAN_PROD['Manufacturer']==man,'Manufacturer'])\n",
        "  # print(f\"{man} :: {len(tdf)} :: {temp.loc[temp['Manufacturer']==man,'MASTER_MAN_NAME']} ::::::::\")\n",
        "  #print(f\"{temp.loc[temp['Manufacturer']==man,'MASTER_MAN_NAME']} ::::::::\")\n",
        "\n",
        "errors=0\n",
        "for man in list(temp['Manufacturer']):\n",
        "  test=SDF[SDF['Manufacturer']==man]\n",
        "  if len(test)>0:\n",
        "    print(man)\n",
        "  errors+=len(test)\n",
        "print(f\" Products with Manufacturer name adjusted__: {corrections:4} of {tofix} with {errors} missed\")\n",
        "\n",
        "SDF.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_mans.csv\",index=False)\n",
        "FDFa.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_keys.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs1pGrtmLArj"
      },
      "source": [
        "# Step 3.3: Clean Product names (Clear out MAN name in products)\n",
        "\n",
        "GOT MESSY but \"it works\"\n",
        "\n",
        "Purppse:  Remove manufacturer names from products so when looking them up in the products table there is a higher score and less likely to add to the table.\n",
        "\n",
        "Product table does not include manufacturer name in the product\n",
        "\n",
        "Adding regex expression to find UOM's and wieghts, thc,cdb ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PlDgS3iLUtq"
      },
      "outputs": [],
      "source": [
        "#Read in man adjusted product list\n",
        "SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_mans.csv\",dtype={'Manufacturer':str,\"Product\":str})\n",
        "#clean out nan's\n",
        "SDF.loc[SDF['Product_size'].isna(),'Product_size']=\"\"\n",
        "SDF.loc[SDF['Product'].isna(),'Product_size']=\"\"\n",
        "SDF.loc[SDF['Manufacturer'].isna(),'Product_size']=\"\"\n",
        "SDF = SDF.dropna(subset=SDF.select_dtypes(np.floating).columns, how='all')\n",
        "SDF = SDF.dropna(subset=['Manufacturer','Product'])\n",
        "SDF=SDF.reset_index()\n",
        "SDF=SDF.drop(['index'],axis=1)\n",
        "#build search term\n",
        "SDF=SDF.copy()\n",
        "SDF['query_dirty']=SDF['Product']+\" \"+SDF['Product_size']\n",
        "SDF['query_dirty']=SDF['query_dirty'].str.replace('|',' ',regex=True)\n",
        "SDF['query_dirty']=SDF['query_dirty'].str.replace('(',' ',regex=True)\n",
        "SDF['query_dirty']=SDF['query_dirty'].str.replace(')',' ',regex=True)\n",
        "SDF['query_dirty']=SDF['query_dirty'].str.replace('-',' ',regex=True)\n",
        "SDF['query']=SDF['query_dirty']\n",
        "\n",
        "SDF['Manufacturer_chk']=SDF['Manufacturer'].str.replace('*','',regex=True)\n",
        "SDF['Manufacturer_chk']=SDF['Manufacturer'].str.replace('-','',regex=True)\n",
        "\n",
        "print(len(set(SDF['query'])))\n",
        "products=list(SDF['query'])\n",
        "corrected=0\n",
        "updated=0\n",
        "adjusted=0\n",
        "t1=t2=t3=t4=t5=t6=0\n",
        "sizes=0\n",
        "\n",
        "for p,product in enumerate(products):\n",
        "  test=product\n",
        "  product=product.lower().replace('*flash sale*','')\n",
        "  maker=SDF.at[p,'Manufacturer_chk'].lower().replace(\".\",\"\").replace('  ','').replace(' AZ','').strip('*')\n",
        "  TEST=True\n",
        "  result1 = re.match('[0-9]*:[0-9]', product)\n",
        "  result2 = re.search(':\\s', product)\n",
        "  result3 = re.search('\\s:\\s', product)\n",
        "  result4 = re.search('\\d pack', product)\n",
        "  # result5 = re.search('\\d\\\\doz', product)\n",
        "  # result6 = re.search('\\d pk', product)\n",
        "  # result7 = re.search('\\d[mg,g,oz]', product)\n",
        "  # result8 = re.search('\\d mg', product)\n",
        "  # result9 = re.search('\\d g', product)\n",
        "  # result10 = re.search('\\d oz', product)\n",
        "  # result11 = re.search('0 mg', product)\n",
        " \n",
        "\n",
        "  #Before I make any changes, pull out the uoms\n",
        "  # if p% 2 ==0:\n",
        "  #   pull_uoms(product,p,SDF)\n",
        "  if p>100000:\n",
        "    break\n",
        "  for c,ch in enumerate(product):\n",
        "    if ch==\":\":\n",
        "      index=c\n",
        "      break\n",
        "  prd_len=len(product)\n",
        "\n",
        "\n",
        "  \n",
        "  if result2 and c/len(maker)<1.1:\n",
        "    #print(f\"{p:5}:{maker:25}{c:3}{c/prd_len:4.2f} {index:3} {len(maker):3}:: {product}\")\n",
        "    if TEST:\n",
        "      man=maker.lower().split()\n",
        "      pro=product.split(':')\n",
        "      prod_list=product.split(':',1)[0].lower().split()\n",
        "      \n",
        "      if man[0]==prod_list[0] and len(pro)>1:\n",
        "        NEW_PROD='_'.join(product.split(':',1)[1:])\n",
        "        corrected+=1\n",
        "        if p%2==0:\n",
        "          #print(f\"{p:5} {corrected:5} {corrected/len(products):.2f}% {man[0]:15} {prod_list[0]:10} *** {product:85} --- {NEW_PROD:60}\")\n",
        "          pass\n",
        "        \n",
        "        TEST=False\n",
        "        t1+=1\n",
        "\n",
        "  if result3 and c/len(maker)<2 and TEST:\n",
        "    #print(f\"{p:5}:{maker:25}{c:3}{c/prd_len:4.2f} {index:3} {len(maker):3}:: {product}\")\n",
        "    if TEST:\n",
        "      man=maker.lower().split()\n",
        "      pro=product.split(':')\n",
        "      prod_list=product.split(':',1)[0].lower().split()\n",
        "      \n",
        "      if man[0]==prod_list[0] and len(pro)>1:\n",
        "        NEW_PROD='_'.join(product.split(':',1)[1:])\n",
        "        corrected+=1\n",
        "        if p%2==0:\n",
        "          #print(f\"{p:5} {corrected:5} {corrected/len(products):.2f}% {man[0]:15} {prod_list[0]:10} *** {product:85} --- {NEW_PROD:60}\")\n",
        "          pass\n",
        "        \n",
        "        TEST=False \n",
        "        t2+=1\n",
        "  if TEST and len(product.replace(maker,\"\",1))>2:\n",
        "    NEW_PROD=product.replace(maker,\"\",1)\n",
        "    if len(NEW_PROD)<len(product):\n",
        "      corrected+=1\n",
        "      TEST=False\n",
        "      t3+=1\n",
        "      #print(f\"{p:5} {corrected:5} {corrected/len(products):.2f}% {maker:15} *** {product:85} ---{NEW_PROD:60}\")\n",
        "  \n",
        "  dist=0\n",
        "  if TEST and len(product)>=len(maker):\n",
        "    dist=0\n",
        "    cont=True\n",
        "    for l,let in enumerate(maker):\n",
        "      if product[l]==let and cont or let==\" \" and cont:\n",
        "        dist=l\n",
        "      else:\n",
        "        cont=False\n",
        "    if dist>0:\n",
        "      TEST=False\n",
        "      NEW_PROD=product[dist+1:]\n",
        "      corrected+=1\n",
        "      t4+=1\n",
        "      # if p%3==0:\n",
        "      #   print(f\"{p:5} {dist} {corrected:5} {corrected/len(products):.2f}% {maker:15} *** {product:85} ---{NEW_PROD:85}\")\n",
        "      #   pass\n",
        "\n",
        "\n",
        "  if TEST:\n",
        "    NEW_PROD=product\n",
        "    corrected+=1\n",
        "    # if p%3==0:\n",
        "    #   print(f\"{p:5} {dist} {corrected:5} {corrected/len(products):.2f}% {maker:15} *** {product:85} ---\")\n",
        "\n",
        "\n",
        "  SDF.at[p,'query']=NEW_PROD.lstrip(\" \").rstrip(\"\").lstrip('+')\n",
        "  if p%100==0:\n",
        "    print(NEW_PROD.lstrip(\" \").rstrip(\"\").lstrip('+'))\n",
        "\n",
        "  if p>100000:\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "THREADS=CORES\n",
        "SDF['THREAD']=SDF.index%THREADS\n",
        "for i in range(THREADS):\n",
        "  tdf=SDF[SDF['THREAD']==i]\n",
        "  tdf=tdf.copy()\n",
        "  tdf.reset_index(inplace=True)\n",
        "  tdf.drop(['index'],axis=1,inplace=True)\n",
        "  MASTER_LIST.append(tdf)\n",
        "  threads=len(MASTER_LIST)\n",
        "\n",
        "\n",
        "PRODUCTS=set(SDF['query'])\n",
        "print(len(PRODUCTS))\n",
        "SDF.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_NO_MAN.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmerSm-szqWX"
      },
      "source": [
        "# STEP 3.4\n",
        "\n",
        "Parse UOM out of product **descriptions**\n",
        "\n",
        "Cleaned product name is in ['query']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_NO_MAN.csv\")\n",
        "products_o=len(set(SDF['Product']))\n",
        "SDF=SDF.drop_duplicates(subset=\"Product_Url\",keep='first')\n",
        "SDF=SDF[~SDF['query'].isna()]\n",
        "SDF = SDF.dropna(subset=['query'])\n",
        "SDF['TAG']=\"\"\n",
        "SDF['BASE_NAME']=SDF['query']\n",
        "SDF=SDF.reset_index()\n",
        "SDF=SDF.drop(['index'],axis=1)\n",
        "#Dictionary of dictionaries of various regex \n",
        "#-Pull out in cascading order: if a==>b and b!==>a do b before a\n",
        "\n",
        "units= {\n",
        "    \"Fractions\"    :r\"(\\s{1}\\d{0,4}\\s{0,1}\\d{1,4}\\s{0,1}\\/\\s{0,1}\\d{1,4}\\s{0,1}(g|oz|mg))\",\n",
        "    \"Ratios\"       :r\"((\\d{1,5}\\s{0,1}((thc:cbd|cbd:thc|thc:cbd:cbn|mg|g\\s|thc|cbd|cbg|cbn){0,2}\\s{0,1}){1,2})((\\/|:)\\s{0,1}\\d{1,5}\\s{0,1}((thc\\s{0,1}:\\s{0,1}cbd|cbd:thc|mg|g\\s|thc|cbd|cbg|cbn){0,2}\\s{0,1}){1,2}){1,4})\",\n",
        "    \"Pack_size\"    :r\"(((\\d{1,4}\\s{0,1}(pk|pack))|(\\s\\d{0,3}\\s{0,1}\\.{0,1}\\d{0,2}(g\\s|mg\\s|oz\\s))\\s{0,1}x\\s{0,1}\\d{1,4})|((\\s\\d{0,3}\\s{0,1}\\.{0,1}\\d{0,2}x\\.{0,1}\\s{0,1}\\d{1,4}(g|mg|oz|ml))\\s{0,1}))\",\n",
        "    'Weight'       :r\"(\\d{0,5}\\s{0,1}[/.]{0,1}\\s{0,1}\\d{1,5}(mg|ml|g|oz)\\s{0,1})\",\n",
        "    'Category_TAG' :r\"((flower|cartridge|pod|pre pack|pre roll|pre rolls|resin|rosin|tablets|hybrid|sativa|indica){1,10})\"\n",
        "\n",
        "}\n",
        "\n",
        "for i in SDF.index:\n",
        "  product=SDF.at[i,'query']\n",
        "  \n",
        "  for k,v in units.items():\n",
        "    result = re.findall(v, product)  \n",
        "    original = product\n",
        "    if result:\n",
        "      for res in result:\n",
        "        product=product.replace(res[0],' ',1)\n",
        "        SDF.at[i,\"TAG\"]+=f\"+{k}<{res[0].replace(' ','').replace('pack','pk')}>\"\n",
        "        SDF.at[i,'BASE_NAME']=product.replace(\"[\",\"\").replace(\"]\",\"\").replace(\":\",\"\").replace(\"  \",\" \").lstrip(\" \").rstrip(\" \")\n",
        "        if k!='Fractions':\n",
        "          SDF.at[i,k]=res[0].replace(' ','').replace('pack','pk')\n",
        "        else:\n",
        "          SDF.at[i,\"Weight\"]=res[0].replace(' ','').replace('pack','pk')\n",
        "        if i%20==0:\n",
        "          print(f\"{i:5} {k:10} {res[0]:20} >><<< {original:60}<<======>>{SDF.at[i,'BASE_NAME']:60}\")\n",
        "\n",
        "\n",
        "SDF[['query','BASE_NAME','TAG','Weight','Ratios','Pack_size']].head(500)\n",
        "\n",
        "products=len(set(SDF['BASE_NAME']))\n",
        "print(products,products_o)\n",
        "SDF.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_NO_MAN_Product_names_parsed.csv\",index=False)"
      ],
      "metadata": {
        "id": "buQVEMt0RLsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3.5.1 Overwrite duplicated names \n",
        "\n",
        "(a=a. now a.='a' for a>a in occurance)\n",
        "\n",
        "Challange:  500mg a and 1000mg a coming back to close to each other.  Tested overweighting 'a' with adding the uom's to the name.  This added more noise.  Going to test with regrex methods to see if 1000 and 500 show up.  if they do, going to reject the change.\n",
        "\n",
        "First filter out the for sure not duplicats.  (There are alot of moving parts to decide on master name)\n",
        "\n"
      ],
      "metadata": {
        "id": "07k8lVUoVnH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_products(LIST_o):\n",
        "  \"\"\"\n",
        "  this could be built out to overwrite other columns to fill in blanks\n",
        "  \"\"\"\n",
        "  #Find numbers\n",
        "  find_numbers=r\"((\\.){0,1}\\d{1,4}\\.{0,1}\\d{0,2})\"\n",
        "\n",
        "\n",
        "  To=time.time()\n",
        "  DFO=LIST_o[0]\n",
        "  ML=LIST_o[1]    #df of all product counts \n",
        "  s1_LIST=list(ML['index'])\n",
        "  #print(DFO.shape)\n",
        "  thread=DFO.at[0,'THREAD']\n",
        "  RDF=pd.DataFrame()\n",
        "  #Index(['index', 'query', 'THREAD']\n",
        "  products=list(DFO['index'])\n",
        "\n",
        "\n",
        "  for p,product in enumerate(products):\n",
        "    \n",
        "    tdf=DFO[DFO['index']==product]\n",
        "    tdf=tdf.copy()\n",
        "    tdf=tdf.reset_index()\n",
        "    tdf=tdf.drop(['index'],axis=1)\n",
        "    tdf.at[0,'product']=product\n",
        "    tdf.at[0,'DUP_PRODUCT_NAME']=\"NO\"\n",
        "    try:\n",
        "      \n",
        "      try:\n",
        "        ops=process.extract(product,s1_LIST)\n",
        "      except:\n",
        "        print(\"ops error\",product)\n",
        "      \n",
        "      try:\n",
        "        total=0\n",
        "        MATCHED=False\n",
        "        for o,op in enumerate(ops):\n",
        "          if op[1]>=70:\n",
        "            total+=1\n",
        "            product1=product.replace(\" \",\"\")\n",
        "            product2=op[0].replace(\" \",\"\")\n",
        "            product1=product.replace(\":\",\"_to_\")\n",
        "            product2=op[0].replace(\":\",\"_to_\")\n",
        "\n",
        "            result = re.findall(find_numbers, product1)\n",
        "            if result:\n",
        "              for res in result:\n",
        "                new=num2words(res[0])\n",
        "                product1=product1.replace(res[0],' ',1)\n",
        "                product1=product1+\" \"+new\n",
        "\n",
        "            result = re.findall(find_numbers, product2)\n",
        "            if result:\n",
        "              for res in result:\n",
        "                new=num2words(res[0])\n",
        "                product2=product2.replace(res[0],' ',1)\n",
        "                product2=product2+\" \"+new\n",
        "      \n",
        "\n",
        "            nop=process.extractOne(product1,[product2])\n",
        "            token=fuzz.token_set_ratio(product1,product2)\n",
        "            ratio=fuzz.ratio(product1,product2)\n",
        "            part_rat=fuzz.partial_ratio(product1,product2)\n",
        "\n",
        "            avg=(nop[1]+token+ratio+part_rat)/4\n",
        "            v1=v2=0\n",
        "            if total>1:\n",
        "          \n",
        "              tdf.at[0,'DUP_PRODUCT_NAME']=\"YES\"\n",
        "              v1=ML.loc[ML['index']==product,'BASE_NAME']\n",
        "              v1=v1.iloc[0]\n",
        "              v2=ML.loc[ML['index']==op[0],'BASE_NAME']\n",
        "              v2=v2.iloc[0]\n",
        "              v1o=v1\n",
        "              v2o=v2\n",
        "              if avg>86 :\n",
        "                MATCHED=True\n",
        "                if v2 >= v1:\n",
        "                  v1=v2\n",
        "                  NEW=op[0]\n",
        "                else:\n",
        "                  NEW=product\n",
        "              \n",
        "                # print(f\"-------------------------------------------------------\\\n",
        "                # \\nProduct[query ]: {product:65}  vs\\\n",
        "                # \\nProduct[search]: {op[0]:65} possibles Scores:[{p:5} {op[1]:4} :: {nop[1]:4} {token:4} {ratio:4} {part_rat:4}:::AVERAGE: {avg:3.2f}] Counts:[{v1o:4} {v2o:4} {v1o/v2o:2.2f}]\")\n",
        "        \n",
        "        \n",
        "        if MATCHED:\n",
        "          tdf.at[0,'MASTER_PRODUCT_NAME']=NEW   \n",
        "        else:\n",
        "          tdf.at[0,'MASTER_PRODUCT_NAME']=product\n",
        "        RDF=RDF.append(tdf,ignore_index=True)\n",
        "        \n",
        "        if p %5==0:\n",
        "          print(f\"[{(p+1)/len(products)*100:3.2f}% Complete] In thread {thread:3} on {p:5} of {len(products):5} products: {product:50} with {total:3} \")\n",
        "        # # try:\n",
        "        #   test=RDF.loc[RDF['DUP_PRODUCT_NAME']==\"YES\",:]\n",
        "        #   if p%50==0:\n",
        "        #     Total_TIME=time.time()-To\n",
        "        #     EST_Total_Time=Total_TIME/((p+1)/len(products))\n",
        "\n",
        "\n",
        "        #     print(f\"[{(p+1)/len(products)*100:6.2f}% Complete] [{len(test)/(p+1)*100:6.2f}% Duplicate] [{Total_TIME/3600:6.2f}Hrs {(EST_Total_Time-Total_TIME)/3600:4.2f} hrs left]==>> In thread {thread:3} on {p:5} of {len(products):5} product: {product:50} :: {total:3} \")\n",
        "        # except:\n",
        "        #   print(\"error getting test\",product)\n",
        "      \n",
        "      except:\n",
        "        print(\"error processing ops\",product)\n",
        "    \n",
        "    except:\n",
        "      print(\"oops error\",product)\n",
        "    # if len(tdf)<1:\n",
        "    #   print(\"ohhhhhhhhhhhhhhhhhh\")\n",
        "    # print(tdf.shape)\n",
        "    # DFO=pull_uoms(product,p,SDF)\n",
        "    # else:\n",
        "    #   query=tdf.at[0,'query']\n",
        "    #   pull_uoms(query,p,tdf)\n",
        "    #   RDF=RDF.append(tdf,ignore_index=True)\n",
        "\n",
        "  return(RDF)\n",
        "\n",
        "\n",
        "def MASTER_LIST_parse_products(THREADS):\n",
        "  SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_NO_MAN_Product_names_parsed.csv\")\n",
        "  print(SDF.columns)\n",
        "\n",
        "\n",
        "  # SDF=SDF[['Dispensary','Product_size', 'Manufacturer', 'Category', 'Listed_content', 'THC%',\n",
        "  #       'CBD%', 'UOM', 'Price', 'query','Manufacturer_chk','Product_Url','mg',\n",
        "  #       'g', 'ratio', 'thc_cbd', 'pk_cont', 'pk', 'strain', 'oz']]\n",
        "\n",
        "  \n",
        "  print(SDF.shape)       \n",
        "  print(SDF.columns)\n",
        "\n",
        "  SDF=SDF.drop_duplicates(subset=\"Product_Url\",keep='first')\n",
        "  SDF=SDF[~SDF['BASE_NAME'].isna()]\n",
        "  SDF = SDF.dropna(subset=['Manufacturer','Product_Url','BASE_NAME'])\n",
        "  SDF=SDF.astype(str)\n",
        "  \"\"\"\n",
        "  Thought about \"overweighting the name to reduce 1000 to 500 matches, but caused more noise \n",
        "  \"\"\"\n",
        "  SDF['BASE_NAME']=SDF['BASE_NAME']+\" :: \"+SDF['Manufacturer']\n",
        "\n",
        "  SDF=SDF.reset_index()\n",
        "  SDF=SDF.drop(['index'],axis=1)\n",
        "\n",
        "  print(SDF.shape)\n",
        "  #SDF['query']=SDF['Manufacturer']+\" \"+SDF['query']\n",
        "  VC=pd.DataFrame(SDF['BASE_NAME'].value_counts())\n",
        "  VC=VC.reset_index()\n",
        "  #make products the index\n",
        "  VC['THREAD']=VC.index%THREADS\n",
        "  MASTER_LIST=[]\n",
        "  for i in range(THREADS):\n",
        "    temp=[]\n",
        "    tdf=VC[VC['THREAD']==i]\n",
        "    print(tdf.shape,VC.shape,len(MASTER_LIST))\n",
        "    tdf=tdf.copy()\n",
        "    tdf=tdf.reset_index()\n",
        "    #not index but level_0 since did not drop index last time\n",
        "    tdf=tdf.drop(['level_0'],axis=1)\n",
        "    tVC=VC.copy()\n",
        "    temp.append(tdf)\n",
        "    temp.append(tVC)\n",
        "    MASTER_LIST.append(temp)\n",
        "  print(tVC.columns) \n",
        "  return(MASTER_LIST)\n",
        "\n",
        "def parse_products_THREADED(MASTER_LIST):\n",
        "  threads=len(MASTER_LIST)\n",
        "  FDF=pd.DataFrame()\n",
        "  FMMDF=pd.DataFrame()\n",
        "  with concurrent.futures.ProcessPoolExecutor(max_workers=threads) as executor:\n",
        "    try:\n",
        "        for r,results in enumerate(executor.map(parse_products,MASTER_LIST)):\n",
        "          FDF=FDF.append(results,ignore_index=True)\n",
        "        print(\"TESTING\")\n",
        "        # path=FDF.at[0,'directory']\n",
        "        # file_name=FDF.at[0,'query_name']\n",
        "        # file_date_stamp=dt.datetime.now()\n",
        "        # file_date_stamp=file_date_stamp.strftime(\"%m_%d_%Y_%H_%M_\")\n",
        "        # FDF.to_csv(join(path,f\"_{file_name}\"),index=False)\n",
        "        # FDF.to_csv(join(path,f\"_{file_date_stamp}_{file_name}\"),index=False)\n",
        "        print(FDF.info())\n",
        "\n",
        "    except:\n",
        "        print(\"OOPS\")\n",
        "  return(FDF)\n",
        "\n",
        "\n",
        "THREADS=CORES\n",
        "MASTER_LIST=MASTER_LIST_parse_products(THREADS)\n",
        "FDF=parse_products_THREADED(MASTER_LIST)\n",
        "#queryy in the numbver of occurances\n",
        "FDF.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_now_parsed_and_overwritten_part_1_of_2_run.csv\",index=False)\n"
      ],
      "metadata": {
        "id": "E1tfTBt-VFaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_now_parsed_and_overwritten_part_1_of_2_run.csv\")\n",
        "FDF=FDF.rename(columns={'BASE_NAME':'NA','product':'BASE_NAME'})\n",
        "SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_NO_MAN_Product_names_parsed.csv\")\n",
        "SDF=SDF.drop_duplicates(subset=\"Product_Url\",keep='first')\n",
        "SDF=SDF[~SDF['BASE_NAME'].isna()]\n",
        "SDF = SDF.dropna(subset=['Manufacturer','Product_Url','BASE_NAME'])\n",
        "SDF=SDF.astype(str)\n",
        "\"\"\"\n",
        "Thought about \"overweighting the name to reduce 1000 to 500 matches, but caused more noise \n",
        "\"\"\"\n",
        "SDF['BASE_NAME']=SDF['BASE_NAME']+\" :: \"+SDF['Manufacturer']\n",
        "FINAL=pd.merge(SDF,FDF,on='BASE_NAME',how='inner')\n",
        "\n",
        "print(SDF.shape,FDF.shape,FINAL.shape)\n",
        "FINAL.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_FINAL.csv\",index=False)\n",
        "DB=FINAL.loc[0:10000,:]\n",
        "DB.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_FINAL_BUILD_DF.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S37231SAtMAw",
        "outputId": "f13bf14f-7f71-4365-ca43-32b5f2030f68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(88799, 57) (25675, 6) (88799, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FINAL.head()"
      ],
      "metadata": {
        "id": "wVwGqWwFwcJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDF.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE4eNL9Cyd9e",
        "outputId": "39d22592-ff39-49eb-cc98-d975d9ef870c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Type', 'Name', 'Abbreviation', 'Capital', 'THREAD', 'Market_Focus',\n",
              "       'DISPS_SRP', 'Pull_Date', 'Dispenary_base_leaf_url', 'Thread_List',\n",
              "       'In_Market_Focus', 'Canada', 'Dispensary', 'Name_Tag', 'total_products',\n",
              "       'Last_update', 'Member_Since', 'google_map', 'Total_Followers',\n",
              "       'Address', 'Street', 'Town', 'State', 'Email', 'Phone', 'Website',\n",
              "       'License', 'Leafly_review_count', 'FILE_NAME', 'total_pages',\n",
              "       'products_on_last_page', 'Products_Page_URL', 'current_page', 'fop',\n",
              "       'Page_Load_Tries', 'Product_Url', 'P_number', 'Variant', 'Product',\n",
              "       'Product_size', 'Manufacturer', 'Category', 'Listed_content', 'THC%',\n",
              "       'CBD%', 'UOM', 'Price', 'Collected_at', 'query_dirty', 'query',\n",
              "       'Manufacturer_chk', 'TAG', 'BASE_NAME', 'Weight', 'Category_TAG',\n",
              "       'Ratios', 'Pack_size'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_now_parsed.csv\")\n",
        "# print(SDF.columns)\n",
        "\n",
        "# SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_now_parsed.csv\")\n",
        "# SDF=SDF[['Dispensary','Product_size', 'Manufacturer', 'Category', 'Listed_content', 'THC%',\n",
        "#       'CBD%', 'UOM', 'Price', 'query','Manufacturer_chk','Product_Url','mg',\n",
        "#        'g', 'ratio', 'thc_cbd', 'pk_cont', 'pk', 'strain', 'oz']]\n",
        "# print(SDF.shape)       \n",
        "# print(SDF.columns)\n",
        "\n",
        "# SDF=SDF.drop_duplicates(subset=\"Product_Url\",keep='first')\n",
        "# SDF=SDF[~SDF['query'].isna()]\n",
        "# SDF = SDF.dropna(subset=['Manufacturer','Product_Url','query'])\n",
        "# SDF=SDF.reset_index()\n",
        "# SDF=SDF.drop(['index'],axis=1)\n",
        "\n",
        "# print(SDF.shape)\n",
        "  \n",
        "# VC=pd.DataFrame(SDF['query'].value_counts())\n",
        "# VC=VC.reset_index()\n",
        "# #No drop to keep column index because it is the OEM's\n",
        "\n",
        "# THREADS=CORES\n",
        "# VC['THREAD']=VC.index%THREADS\n",
        "# VC.head(100)\n",
        "# MASTER_LIST=[]\n",
        "# for i in range(THREADS):\n",
        "#   temp=[]\n",
        "#   tdf=VC[VC['THREAD']==i]\n",
        "#   print(tdf.shape,VC.shape,len(MASTER_LIST))\n",
        "#   tdf=tdf.copy()\n",
        "#   tdf=tdf.reset_index()\n",
        "#   #not index but level_0 since did not drop index last time\n",
        "#   tdf=tdf.drop(['level_0'],axis=1)\n",
        "#   tVC=VC.copy()\n",
        "#   temp.append(tdf)\n",
        "#   temp.append(tVC)\n",
        "#   MASTER_LIST.append(temp)\n",
        "\n",
        "\n",
        "# print(tdf.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SZvK5B5WMh9",
        "outputId": "739e9659-b558-4ad7-a3b1-5831096b37b9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Dispensary', 'Name_Tag', 'total_products', 'Product_size',\n",
            "       'Manufacturer', 'Category', 'Listed_content', 'THC%', 'CBD%', 'UOM',\n",
            "       'Price', 'query', 'Manufacturer_chk', 'Product_Url', 'THREAD', 'mg',\n",
            "       'g', 'ratio', 'thc_cbd', 'pk_cont', 'pk', 'strain', 'oz'],\n",
            "      dtype='object')\n",
            "(89035, 20)\n",
            "Index(['Dispensary', 'Product_size', 'Manufacturer', 'Category',\n",
            "       'Listed_content', 'THC%', 'CBD%', 'UOM', 'Price', 'query',\n",
            "       'Manufacturer_chk', 'Product_Url', 'mg', 'g', 'ratio', 'thc_cbd',\n",
            "       'pk_cont', 'pk', 'strain', 'oz'],\n",
            "      dtype='object')\n",
            "(89035, 20)\n",
            "(741, 3) (29627, 3) 0\n",
            "(741, 3) (29627, 3) 1\n",
            "(741, 3) (29627, 3) 2\n",
            "(741, 3) (29627, 3) 3\n",
            "(741, 3) (29627, 3) 4\n",
            "(741, 3) (29627, 3) 5\n",
            "(741, 3) (29627, 3) 6\n",
            "(741, 3) (29627, 3) 7\n",
            "(741, 3) (29627, 3) 8\n",
            "(741, 3) (29627, 3) 9\n",
            "(741, 3) (29627, 3) 10\n",
            "(741, 3) (29627, 3) 11\n",
            "(741, 3) (29627, 3) 12\n",
            "(741, 3) (29627, 3) 13\n",
            "(741, 3) (29627, 3) 14\n",
            "(741, 3) (29627, 3) 15\n",
            "(741, 3) (29627, 3) 16\n",
            "(741, 3) (29627, 3) 17\n",
            "(741, 3) (29627, 3) 18\n",
            "(741, 3) (29627, 3) 19\n",
            "(741, 3) (29627, 3) 20\n",
            "(741, 3) (29627, 3) 21\n",
            "(741, 3) (29627, 3) 22\n",
            "(741, 3) (29627, 3) 23\n",
            "(741, 3) (29627, 3) 24\n",
            "(741, 3) (29627, 3) 25\n",
            "(741, 3) (29627, 3) 26\n",
            "(740, 3) (29627, 3) 27\n",
            "(740, 3) (29627, 3) 28\n",
            "(740, 3) (29627, 3) 29\n",
            "(740, 3) (29627, 3) 30\n",
            "(740, 3) (29627, 3) 31\n",
            "(740, 3) (29627, 3) 32\n",
            "(740, 3) (29627, 3) 33\n",
            "(740, 3) (29627, 3) 34\n",
            "(740, 3) (29627, 3) 35\n",
            "(740, 3) (29627, 3) 36\n",
            "(740, 3) (29627, 3) 37\n",
            "(740, 3) (29627, 3) 38\n",
            "(740, 3) (29627, 3) 39\n",
            "Index(['index', 'query', 'THREAD'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKhP3RnYxG77",
        "outputId": "87870dc4-1e10-4b6d-a5b3-a009ca7b28f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1684: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = infer_fill_value(value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 4.0    0 ll's bells popcorn   7g        False lls bells popcorn   7g         98\n",
            " 2.0    4 milk chocolate jamocha 25      False milk chocolate jamocha 25      98\n",
            " 4.0   11 lls bells popcorn   7g         False ll's bells popcorn   7g        98\n",
            " 2.0    7 milk chocolate rolling 25      False milk chocolate rolling 25      98\n",
            "12.0    4 bobby blue's buckshots 3.      False bobby blues buckshots 3.5      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "22.0    1 ev premium purple punch .      False ev premium purple punch ,      100\n",
            "13.0   12 peanut butter 100mg            False peanut butter 100mg            100\n",
            "10.0   26 swift lifts   mini pre ro      False swift lifts mini pre roll      98\n",
            "12.0   26 frosty snowcones clear ca      False frosty snowcone clear car      98\n",
            "13.0   13 brownie bites 400mg            False brownie bites 400mg            100\n",
            "error 0 order online  \n",
            " 6.0    4 's medicines tropical pun      False 's medicine tropical punc      99\n",
            "error in product loop\n",
            "22.0    4 ev premium purple punch ,      False ev premium purple punch .      100\n",
            "12.0   28 frosty snowcone clear car      False frosty snowcones clear ca      98\n",
            "16.0    1 awaken tincture 500mg          False awaken tincture 1500mg         98\n",
            " 6.0    5 's medicine tropical punc      False 's medicines tropical pun      99\n",
            "16.0    7 awaken tincture 1500mg         False awaken tincture 500mg          98\n",
            "33.0   10 single 100mg sativa            False single 100mg sativa            100\n",
            "22.0    6 ev premium 1:1 ice cream       False ev premium 1:1 ice cream       99\n",
            "21.0    3 champagne 100mg                False champagne 100mg                100\n",
            "16.0    4 sdv   marijuarita   100mg      False sdv   marijuarita   10mg       98\n",
            "16.0    6 sdv   cannabernet   10mg       False sdv   cannabernet   100mg      98\n",
            "16.0    8 sdv   cannabernet   100mg      False sdv   cannabernet   10mg       98\n",
            "16.0    9 sdv   marijuarita   10mg       False sdv   marijuarita   100mg      98\n",
            "27.0   13 willie's reserve pre roll      False willie's reserve pre roll      98\n",
            " 6.0   12 's medicines indigo daydr      False 's medicine indigo daydre      99\n",
            "12.0   43 bobby blues buckshots 3.5      False bobby blue's buckshots 3.      98\n",
            "38.0   10 blondie bites [5pk] 50mg       False blondie bites [5pk] 250mg      98\n",
            "10.0   48 swift lifts mini pre roll      False swift lifts   mini pre ro      98\n",
            "17.0    2 capsules   relief   200mg      False capsules   relief   200mg      100\n",
            "24.0    1 **medical only** pure gum      False **medical only** pure gum      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "22.0   12 ex cured reisn premium tk      False ex cured resin premium tk      98\n",
            "error 0 order online  \n",
            "27.0   21 willie's reserve pre roll      False willie's reserve pre roll      98\n",
            "34.0   30 premium pre roll 1g   for      False premium preroll 1g   fore      98\n",
            "error in product loop\n",
            "14.0   32 pre roll 2.5g   dtla og        False preroll 2.5g   dtla og         98\n",
            "17.0    8 **medical only** kindred       False **medical only** kindred       98\n",
            "31.0   13 blueberry 1:1 gummies          False lueberry 1:1 gummies           98\n",
            "21.0   23 hocolate strawberry 100mg      False chocolate strawberry 100m      98\n",
            "30.0   33 blck label   wonder woman      False blck label   wonder woman      98\n",
            "36.0    8 blue raspberry 100mg           False blue raspberry 100mg           100\n",
            "13.0   35 brownie bites 400mg            False brownie bites 400mg            100\n",
            "22.0   17 ev premium 1:1 ice cream       False ev premium 1:1 ice cream       99\n",
            "36.0   14 blue raspberry 100mg           False blue raspberry 100mg           100\n",
            "11.0   26 sour watermelon wedges         False sour watermelons wedges        99\n",
            "13.0   40 brownie 100mg                  False brownie 100mg                  100\n",
            "14.0   46 preroll 2.5g   dtla og         False pre roll 2.5g   dtla og        98\n",
            "20.0    9 half pint shatter 1 g          False half pint shatter 1g           98\n",
            "34.0   54 premium preroll 1g   fore      False premium pre roll 1g   for      98\n",
            "30.0   46 blck label   wonder woman      False blck label   wonder woman      98\n",
            "21.0   36 champagne 100mg                False champagne 100mg                100\n",
            " 6.0   42 's medicine indigo daydre      False 's medicines indigo daydr      99\n",
            "21.0   38 milk chocolate almond bit      False milk chocolate almond bit      98\n",
            "32.0   32 bliss tablet 1:1 cbd, 2 p      False bliss tablet 1:1 cbd, 20       99\n",
            "32.0   32 bliss tablet 1:1 cbd, 2 p      False bliss tablet 1:1 cbd, 2 p      99\n",
            "24.0   35 **medical only** pure gum      False **medical only** pure gum      98\n",
            "34.0   18 health oil   1g   indica       False health oil   1g   indica       98\n",
            "22.0   26 ev premium 24k gold punch      False ev premium 24k gold punch      98\n",
            "33.0   66 single 100mg sativa            False single 100mg sativa            100\n",
            "24.0   40 caramels 100mg                 False caramels 100mg                 100\n",
            "11.0   43 sour watermelons wedges        False sour watermelon wedges         99\n",
            "26.0   42 mac x super lemon haze 3.      False mac x super lemon haze 3.      100\n",
            "13.0   61 snickerdoodle cookies          False snickerdoodle cookie           98\n",
            "error 0 order online  \n",
            "36.0    4 mandarin orange 100mg          False mandarin orange 10mg           98\n",
            " 2.0   47 milk chocolate jamocha 25      False milk chocolate jamocha 25      98\n",
            "13.0   62 peanut butter cookie           False peanut butter cookies          98\n",
            "error in product loop\n",
            "23.0    6 rice rolling papers 1 ½\"       False rice rolling papers 1 ¼\"       100\n",
            " 6.0   67 's medicine dr. freeze sh      False 's medicines dr. freeze s      98\n",
            "error 1 order online  \n",
            "error in product loop\n",
            "error 2 order online  \n",
            "23.0   11 rice rolling papers 1 ¼\"       False rice rolling papers 1 ½\"       100\n",
            "error in product loop\n",
            "35.0    6 brownie bites [5pk] 50mg       False brownie bites [5pk] 250mg      98\n",
            "11.0   52 sour watermelons wedges        False sour watermelon wedges         99\n",
            "36.0    7 sir newton's mandarin ora      False sir newton's mandarin ora      99\n",
            " 6.0   73 's medicines dr. freeze s      False 's medicine dr. freeze sh      98\n",
            "13.0   69 peanut butter 100mg            False peanut butter 100mg            100\n",
            "34.0   49 health oil   1g   indica       False health oil   1g   indica       98\n",
            "38.0   57 blondie bites [5pk] 250mg      False blondie bites [5pk] 50mg       98\n",
            "13.0   71 snickerdoodle cookie           False snickerdoodle cookies          98\n",
            " 2.0   55 dark chocolate razelberri      False dark chocolate razelberri      98\n",
            "13.0   72 brownie 100mg                  False brownie 100mg                  100\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "24.0   65 **medical only** pure gum      False **medical only** pure gum      98\n",
            "36.0   16 kiwi strawberry 10mg           False kiwi strawberry 100mg          98\n",
            "32.0   51 genius tablet 1:1 cbd, 2       False genius tablet 1:1 cbd, 20      99\n",
            "26.0   60 mac x super lemon haze 3.      False mac x super lemon haze 3.      100\n",
            "21.0   79 chocolate strawberry 100m      False hocolate strawberry 100mg      98\n",
            "24.0   74 caramels 100mg                 False caramels 100mg                 100\n",
            "11.0   74 sour watermelon wedges         False sour watermelons wedges        99\n",
            "19.0    0 lass 18\" beaker waterpipe      False lass 15\" beaker waterpipe      98\n",
            "36.0   25 sir newton's peppermint m      False sir newton's peppermint m      98\n",
            "19.0    1 lass 15\" beaker waterpipe      False lass 18\" beaker waterpipe      98\n",
            "24.0   81 **medical only** pure gum      False **medical only** pure gum      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "36.0   27 kiwi strawberry 100mg          False kiwi strawberry 10mg           98\n",
            "21.0   92 milk chocolate almond bit      False milk chocolate almond bit      98\n",
            "30.0   13 reen poison pre roll sing      False reen poison pre roll sing      98\n",
            " 8.0   68 3.5g pre pack hybrid flow      False 3.5g pre pack hybrid flow      99\n",
            "32.0   65 go tablet 1:1 cbd, 2 piec      False go tablet 1:1 cbd, 2 piec      99\n",
            "32.0   65 go tablet 1:1 cbd, 2 piec      False go tablet 1:1 cbd, 20 pie      98\n",
            " 3.0   33 candy cake live rosin tan      False candy cake live rosin tan      98\n",
            "13.0  100 peanut butter cookies          False peanut butter cookie           98\n",
            "13.0    0 sour sensi stripes 100mg       False sour sensi stripes 100mg       100\n",
            "13.0    0 sour sensi stripes 100mg       False sour sensi stripes100mg        98\n",
            "36.0   37 sir newton's mandarin ora      False sir newton's mandarin ora      99\n",
            "14.0   46 enhance intimacy oil 150m      False enhance intimacy oil 150       98\n",
            "13.0    9 peanut butter 100mg            False peanut butter 100mg            100\n",
            "35.0   44 brownie bites [5pk] 250mg      False brownie bites [5pk] 50mg       98\n",
            "13.0   12 peach gummies   100mg          False peach gummies   100mg          100\n",
            " 3.0   56 candy cake live rosin tan      False candy cake live rosin tan      98\n",
            "13.0   13 fruit punch 100mg              False fruit punch 100mg              100\n",
            "14.0   67 evolve gel 500 mg 1:1          False evolve gel 500mg 1:1           98\n",
            "32.0   79 chill 5:1   1906 tablets       False chill 5:1   1906 tablets       98\n",
            "14.0   69 enhance intimacy oil 150       False enhance intimacy oil 150m      98\n",
            "31.0   58 exotic yuzu 2:1 [10pk] 20      False exotic yuzu 2:1 [10pk] 20      99\n",
            "11.0   16 anytime caps 100mg 10x10m      False anytime caps 100 mg 10x10      98\n",
            "32.0   81 go tablet 1:1 cbd, 2 piec      False go tablet 1:1 cbd, 2 piec      99\n",
            "14.0   71 evolve gel 500mg 1:1           False evolve gel 500 mg 1:1          98\n",
            "32.0   81 go tablet 1:1 cbd, 2 piec      False go tablet 1:1 cbd, 20 pie      99\n",
            "11.0   18 anytime caps 100 mg 10x10      False anytime caps 100mg 10x10m      98\n",
            "17.0   81 **medical only** kindred       False **medical only** kindred       98\n",
            "30.0   36 reen poison pre roll sing      False reen poison pre roll sing      98\n",
            "13.0   21 sour sensi stripes100mg        False sour sensi stripes 100mg       98\n",
            "13.0   21 sour sensi stripes100mg        False sour sensi stripes 100mg       98\n",
            "36.0   53 sir newton's old fashione      False sir newtons old fashioned      99\n",
            "16.0   64 smart battery techniq  si      False smart battery techniq sil      98\n",
            "error 0 order online  \n",
            "13.0   22 sour sensi stripes 100mg       False sour sensi stripes 100mg       100\n",
            "13.0   22 sour sensi stripes 100mg       False sour sensi stripes100mg        98\n",
            "29.0    2 3.5g pre pack flower dosi      False 3.5g pre pack flower dosi      98\n",
            "error in product loop\n",
            "error 1 order online  \n",
            "14.0    5 orange kush [12oz] 10mg        False orange kush [12oz] 100mg       98\n",
            "17.0   85 body capsules 1:1 cbd:thc      False body capsules 1:1 cbd:thc      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "14.0    7 orange kush [12oz] 100mg       False orange kush [12oz] 10mg        98\n",
            "error in product loop\n",
            "error 3 order online  \n",
            "error 1 order online  \n",
            "35.0   57 french chocolate brownie       False french chocolate brownie       99\n",
            "36.0   57 sir newtons old fashioned      False sir newton's old fashione      99\n",
            "14.0    8 purple passion [12oz] 100      False purple passion [12oz] 10m      98\n",
            "error in product loop\n",
            "32.0   86 genius tablet 1:1 cbd, 20      False genius tablet 1:1 cbd, 2       99\n",
            "30.0   41 lem dog pre roll single 0      False lem dog pre roll single 0      98\n",
            "error in product loop\n",
            "14.0   12 purple passion [12oz] 10m      False purple passion [12oz] 100      98\n",
            " 2.0   92 dark chocolate razelberri      False dark chocolate razelberri      98\n",
            "13.0   32 cherry gummies   100mg         False cherry gummies   100mg         100\n",
            "11.0   40 daycaps 100mg 10x10mg          False day caps 100mg 10x10mg         98\n",
            "13.0   33 cherry gummies   100mg         False cherry gummies   100mg         100\n",
            "32.0   91 go tablet 1:1 cbd, 20 pie      False go tablet 1:1 cbd, 2 piec      99\n",
            "13.0   35 lemon gummies 100mg            False lemon gummies 100mg            100\n",
            "32.0   91 go tablet 1:1 cbd, 20 pie      False go tablet 1:1 cbd, 2 piec      98\n",
            "36.0   66 sir newton's kiwi strawbe      False sir newton's kiwi strawbe      99\n",
            "39.0   29 bubblegum kush [600mg]         False bubblegum kush   600mg         98\n",
            "26.0    2 chill pill nighttime thc       False chill pill nighttime thc       98\n",
            "39.0   32 bubblegum kush   600mg         False bubblegum kush [600mg]         98\n",
            "14.0    2 blue raspberry sucker 10       False blue raspberry sucker 10m      98\n",
            "13.0   42 cherry gummies 100 mg          False cherry gummies 100mg           98\n",
            "11.0   56 day caps 100mg 10x10mg         False daycaps 100mg 10x10mg          98\n",
            "19.0   10 cartridge ccell 500mg rai      False cartridge ccell 500mg rai      99\n",
            "36.0   68 sir newtons mandarin oran      False sir newtons mandarin oran      99\n",
            "29.0   24 3.5g pre pack flower dosi      False 3.5g pre pack flower dosi      98\n",
            "11.0   58 day caps 100mg 20x5mg          False daycaps 100mg 20x5mg           98\n",
            "25.0   67 grand daddy purple .5g         False grand daddy purple 0.5g        98\n",
            "39.0    0 ogeez! orang creamsicle i      False ogeez! orange creamsicle       98\n",
            "error 0 order online  \n",
            "39.0    7 ogeez! orange creamsicle       False ogeez! orang creamsicle i      98\n",
            "error in product loop\n",
            "14.0    3 lemon tea cake 100mg           False lemon tea cake 100mg           100\n",
            " 8.0   21 classic brownie 100 mg         False classic brownie 100mg          98\n",
            "14.0    3 lemon tea cake 100mg           False lemon tea cake 100 mg          98\n",
            "36.0   70 sir newtons peach mango 1      False sir newtons peach mango 1      98\n",
            "11.0   64 daycaps 100mg 20x5mg           False day caps 100mg 20x5mg          98\n",
            " 8.0   22 **medical only** aunt ell      False **medical only** aunt ell      98\n",
            " 8.0   25 classic brownie 100mg          False classic brownie 100 mg         98\n",
            "13.0   53 fruit punch 100mg              False fruit punch 100mg              100\n",
            "36.0   73 sir newton's peppermint m      False sir newton's peppermint m      98\n",
            "38.0   11 blueberry pate de fruit g      False blueberry pate de fruit g      99\n",
            " 8.0   26 **medical only** aunt ell      False **medical only** aunt ell      98\n",
            "13.0   54 cherry gummies 100mg           False cherry gummies 100 mg          98\n",
            "27.0    6 apple fritters disposable      False apple fritter disposable       98\n",
            "32.0    1 fatso cured sugar 1 g          False fatso cured sugar 1g           98\n",
            "27.0   10 apple fritter disposable       False apple fritters disposable      98\n",
            "36.0   80 sir newton's kiwi strawbe      False sir newton's kiwi strawbe      99\n",
            "13.0   62 lemon gummies 100mg            False lemon gummies 100mg            100\n",
            "32.0    9 fatso cured sugar 1g           False fatso cured sugar 1 g          98\n",
            "13.0   64 peanut butter 100mg            False peanut butter 100mg            100\n",
            "16.0   89 smart battery techniq sil      False smart battery techniq  si      98\n",
            "13.0   67 watermelon slices 100mg        False watermelon slices 10mg         98\n",
            "31.0   83 yuzu cbd:thc 2:1  250 mg       False yuzu cbd:thc 2:1   250 mg      98\n",
            "26.0   20 rainbow belts 250mg            False rainbow belts 250mg            100\n",
            "38.0   26 paté de fruit gummies pin      False paté de fruit gummies pin      98\n",
            "38.0   27 paté de fruit gummies gua      False paté de fruit gummies gua      98\n",
            "14.0    9 lemon tea cake 100mg           False lemon tea cake 100mg           100\n",
            "14.0    9 lemon tea cake 100mg           False lemon tea cake 100 mg          98\n",
            "13.0   80 watermelon slices 10mg         False watermelon slices 100mg        98\n",
            "36.0   93 mandarin orange 10mg           False mandarin orange 100mg          98\n",
            "25.0   92 grand daddy purple 0.5g        False grand daddy purple .5g         98\n",
            "36.0   94 sir newtons kiwi strawber      False sir newtons kiwi strawber      99\n",
            "36.0   95 sir newtons kiwi strawber      False sir newtons kiwi strawber      99\n",
            "37.0    2 madi's stoned ground pean      False madi's stoned ground pean      98\n",
            "13.0   91 peach gummies   100mg          False peach gummies   100mg          100\n",
            "36.0   99 sir newtons black cherry       False sir newtons black cherry       99\n",
            "26.0   32 s  sour cherry gummy drop      False s sour cherry gummy drops      98\n",
            "26.0   32 s  sour cherry gummy drop      False s   sour cherry gummy dro      98\n",
            "38.0   41 paté de fruit gummies gua      False paté de fruit gummies gua      98\n",
            " 7.0   36 canary 1:1 chill .5g h         False canary 16:1 chill .5g h        98\n",
            "37.0   20 madi's stoned ground pean      False madi's stoned ground pean      98\n",
            "20.0   64 half pint shatter 1g           False half pint shatter 1 g          98\n",
            "14.0   13 dark chocolate bar  h   1      False dark chocolate bar  h   1      98\n",
            "26.0   34 vegan organic gummy bears      False vegan organic gummy bears      100\n",
            "27.0   15 dark chocolate 100mg           False dark chocolate 100 mg          98\n",
            "38.0   47 paté de fruit gummies pin      False paté de fruit gummies pin      98\n",
            " 9.0    3 space doctor terp sugar 1      False space doctor terp sugar 1      98\n",
            "14.0   15 spicy southwest pretzels       False spicy southwest pretzels       100\n",
            "15.0   63 1000mg live resin cartrid      False 1000mg live resin cartrid      98\n",
            " 9.0    5 space doctor terp sugar 1      False space doctor terp sugar 1      98\n",
            "36.0   24 1:1 pain relief roll on 1      False 1:1 pain relief roll on 1      100\n",
            "36.0   42 1:1 pain relief roll on 1      False 1:1 pain relief roll on 1      100\n",
            " 9.0   17 chemfusion cookie dough 1      False chemfusion cookie dough 1      98\n",
            "26.0   47 chill pill nighttime thc       False chill pill nighttime thc       98\n",
            "14.0   21 tropical gummies 100mg         False tropical gummies 100mg         100\n",
            "38.0   62 blueberry pate de fruit g      False blueberry pate de fruit g      99\n",
            "16.0    1 lr badder   truck driver       False lr badder   truck driver:      98\n",
            "33.0    3 stoney prickly pear lemon      False stoney prickly pear lemon      100\n",
            "28.0    1 ! watermelon s 100mg           False watermelon s 100mg             100\n",
            "19.0   27 rick simpson oil 2:1 thc/      False rick simpson oil 1:1 thc/      98\n",
            "14.0   23 sweet & savory pretzels 1      False sweet & savory pretzels 1      100\n",
            "38.0   71 paté de fruit gummies str      False paté de fruit gummies str      98\n",
            "38.0   72 paté de fruit gummies str      False paté de fruit gummies str      98\n",
            " 8.0    0 blueberry belts 100mg          False blueberry belts 100mg          100\n",
            " 8.0    0 blueberry belts 100mg          False blueberry belts 100 mg         98\n",
            "38.0   73 gummies 500mg   guava          False gummies 500mg  guava           98\n",
            "26.0   55 rainbow belts 250mg            False rainbow belts 250mg            100\n",
            "26.0   56 s sour cherry gummy drops      False s  sour cherry gummy drop      98\n",
            " 9.0   39 y x snowman crumble 0.5 g      False y x snowman crumble 0.5g       98\n",
            "14.0   27 lood orange hard candies       False blood orange hard candies      98\n",
            "28.0    7 raspberry orange gummies       False raspberry orange gummies       98\n",
            "26.0   59 dried cantaloupe 100mg         False dried cantaloupe 100mg         100\n",
            "26.0   59 dried cantaloupe 100mg         False dried cantaloupes 100mg        98\n",
            "38.0   85 gummies 500mg  guava           False gummies 500mg   guava          98\n",
            " 9.0   48 chemfusion cookie dough 1      False chemfusion cookie dough 1      98\n",
            "16.0   19 lr badder   franken cakes      False lr badder   franken cakes      98\n",
            " 9.0   51 y x snowman crumble 0.5g       False y x snowman crumble 0.5 g      98\n",
            "28.0   10 raspberry orange rso 100m      False raspberry orange rso 100m      100\n",
            "24.0   37 tru infusion   salve 1:1       False tru infusion   salve 1:1       98\n",
            " 8.0    8 watermelon belts 1000mg        False watermelon belts 100mg         98\n",
            " 8.0    8 watermelon belts 1000mg        False watermelon belts 1000 mg       98\n",
            " 8.0    8 watermelon belts 1000mg        False watermelon belts 100mg         98\n",
            "33.0   14 sleepy blackberry acai gu      False sleepy blackberry acai gu      100\n",
            "26.0   67 dried pineapple 100mg          False dried pineapple 100 mg         98\n",
            "28.0   16 !   raspberry orange   10      False raspberry orange   100mg       100\n",
            " 8.0   11 pink lemonade belts 300mg      False pink lemonade belts 300mg      100\n",
            " 8.0   11 pink lemonade belts 300mg      False pink lemonade belts 300 m      98\n",
            "20.0   88 sherb cake shatter 1 g         False sherb cake shatter 1g          98\n",
            "33.0   20 100mgthc : 100mgcbd : 100      False 100mgthc : 100mgcbd : 100      98\n",
            "14.0   33 red hot cinnamon hard can      False red hot cinnamon hard can      100\n",
            "14.0   34 watermelon hard candies 1      False watermelon hard candies 1      100\n",
            "26.0   75 dried pineapple 100 mg         False dried pineapple 100mg          98\n",
            " 8.0   15 strawberry/banana belts 1      False strawberry banana belts 1      100\n",
            " 8.0   15 strawberry/banana belts 1      False strawberry banana belts 1      100\n",
            "34.0   12 1:10 unflavored 300mg          False 1:1 unflavored 300mg           98\n",
            " 8.0   18 strawberry belts 300mg         False strawberry belts 300mg         100\n",
            " 8.0   18 strawberry belts 300mg         False strawberry belts 300 mg        98\n",
            "16.0   46 lr badder   franken cakes      False lr badder   franken cakes      98\n",
            "13.0    8 milk chocolate 1000mg          False milk chocolate 100mg           98\n",
            " 8.0   20 cotton fluff belts 100mg       False cotton fluff belts 100mg       100\n",
            " 8.0   20 cotton fluff belts 100mg       False cotton fluff belts 100 mg      98\n",
            " 8.0   20 cotton fluff belts 100mg       False cotton fluff belt 100mg        98\n",
            "11.0   42 1g rosin gorillawreck          False 1g rosin gorilla wreck         98\n",
            "33.0   28 gummies   happy pom necta      False gummies   happy pom necta      98\n",
            " 8.0   23 blue raz rings 300mg           False blue raz rings 300 mg          98\n",
            " 8.0   25 blueberry belts 300 mg         False blueberry belts 300mg          98\n",
            "33.0   33 100mgthc : 100mgcbg : ras      False 100mgthc : 100mgcbg raspb      98\n",
            "13.0   14 cookies & cream 100mg          False cookies & cream 100mg          100\n",
            "19.0   39 exploding rockz 100mg gra      False exploding rockz 10mg grap      98\n",
            "26.0   88 dried cantaloupes 100mg        False dried cantaloupe 100mg         98\n",
            "26.0   88 dried cantaloupes 100mg        False dried cantaloupe 100mg         98\n",
            " 8.0   27 apple rings 300mg              False apple rings 300mg              100\n",
            " 8.0   30 cherry rings 300mg             False cherry rings 300mg             100\n",
            "26.0   94 chill pill anytime thc ca      False chill pill anytime thc ca      98\n",
            "15.0    9 vibes the cali hemp   2 g      False vibes the cali hemp   3 g      98\n",
            "15.0    9 vibes the cali hemp   2 g      False vibes the cali hemp   1 g      98\n",
            "15.0   12 vibes the cali hemp   3 g      False vibes the cali hemp   2 g      98\n",
            "15.0   12 vibes the cali hemp   3 g      False vibes the cali hemp   1 g      98\n",
            "15.0   15 vibes the cali hemp   1 g      False vibes the cali hemp   2 g      98\n",
            "15.0   15 vibes the cali hemp   1 g      False vibes the cali hemp   3 g      98\n",
            "14.0   44 tropical gummies 100mg         False tropical gummies 100mg         100\n",
            " 9.0   37 classic rolling papers 1       False classic rolling papers 1       100\n",
            "16.0   78 lr badder   truck driver:      False lr badder   truck driver       98\n",
            " 8.0   39 cotton candy belts 300mg       False cotton candy belts 300mg       100\n",
            " 9.0   58 classic rolling papers 1       False classic rolling papers 1       100\n",
            "15.0    6 sunset sherbet x kush min      False sunset sherbert x kush mi      99\n",
            "28.0   52 raspberry orange gummies       False raspberry orange gummies       98\n",
            "25.0   44 live hash rosin cartridge      False live hash rosin cartridge      99\n",
            " 8.0   45 cotton fluff belts 300mg       False cotton fluff belts 300mg       100\n",
            " 8.0   45 cotton fluff belts 300mg       False cotton fluff belts 300 mg      98\n",
            "39.0   91 3:1 milk chocolate w/ sea      False 3:1 milk chocolate w/ sea      99\n",
            "33.0   54 stoney prickly pear lemon      False stoney prickly pear lemon      100\n",
            "27.0   93 milk chocolate 100 mg          False milk chocolate 100mg           98\n",
            " 8.0   46 strawberry apple belts 30      False strawberry apple belts 30      98\n",
            " 8.0   46 strawberry apple belts 30      False strawberry apple belts 30      98\n",
            "31.0   19 cinderella 99 3.5.g rff        False cinderella 99 3.5g rff         98\n",
            "33.0   56 sleepy blackberry acai gu      False sleepy blackberry acai gu      100\n",
            " 8.0   48 strawberry belts 300 mg        False strawberry belts 300mg         98\n",
            " 8.0   48 strawberry belts 300 mg        False strawberry belts 300mg         98\n",
            "34.0   77 1:1 unflavored 300mg           False 1:10 unflavored 300mg          98\n",
            " 8.0   51 blue raz rings 100mg           False blue raz rings 100 mg          98\n",
            "28.0   70 raspberry orange rso 100m      False raspberry orange rso 100m      100\n",
            " 8.0   52 apple rings 300mg              False apple rings 300mg              100\n",
            " 8.0   53 pink lemonade belts 100 m      False pink lemonade belts 100mg      98\n",
            " 8.0   53 pink lemonade belts 100 m      False pink lemonade belts 100mg      98\n",
            "28.0   75 ! blackberries and cream       False blackberries and cream s       100\n",
            "13.0   32 dark chocolate bar   10 p      False dark chocolate bar   10 p      98\n",
            "33.0   65 stoney prickly pear lemon      False stoney prickly pear lemon      100\n",
            "33.0   69 's happy pomegranate nect      False 's happy pomegranate nect      98\n",
            " 8.0   59 watermelon rings 100mg         False watermelon rings 100mg         100\n",
            " 8.0   59 watermelon rings 100mg         False watermelon rings 100 mg        98\n",
            "14.0   59 lemon tea cake 100 mg          False lemon tea cake 100mg           98\n",
            "14.0   59 lemon tea cake 100 mg          False lemon tea cake 100mg           98\n",
            " 8.0   61 mango belts 100mg              False mango belts 100mg              100\n",
            "33.0   72 stoney: prickly pear lemo      False stoney prickly pear lemon      98\n",
            " 8.0   64 rainbow belts 300mg            False rainbow belts 300mg            100\n",
            " 8.0   66 strawberry banana belts 3      False strawberry/banana belts 3      100\n",
            "13.0   46 1000mg milk chocolate bar      False 100mg milk chocolate bar       98\n",
            "31.0   80 cinderella 99 3.5g rff         False cinderella 99 3.5.g rff        98\n",
            " 8.0   67 strawberry apple belts 30      False strawberry apple belts 30      100\n",
            " 8.0   67 strawberry apple belts 30      False strawberry apple belts 30      98\n",
            "21.0   79 milk chocolate 100 mg          False milk chocolate 100mg           98\n",
            "23.0   18 **medical only** ogeez! g      False **medical only** ogeez! g      98\n",
            " 8.0   71 watermelon rings 300mg         False watermelon rings 300mg         100\n",
            " 8.0   71 watermelon rings 300mg         False watermelon rings 300 mg        98\n",
            "23.0   22 gummies 100mg   blackberr      False gummies 300mg   blackberr      98\n",
            "23.0   23 **medical only** ogeez! g      False **medical only** ogeez! g      98\n",
            " 2.0   99 strawberry mango potion d      False strawberry mango potion d      98\n",
            " 2.0   99 strawberry mango potion d      False strawberry mango potion d      98\n",
            "23.0   27 copia ogeez blackberries       False copia ogeez blackberries       98\n",
            "16.0    0 peach 2:1 cbd:thc              False peach 2:1 cbd/thc              100\n",
            "33.0   84 300mgthc : 300mgcbd : 300      False 300mgthc : 300mgcbd : 300      98\n",
            "23.0   33 sativa blackberries and c      False sativa blackberries and c      98\n",
            " 8.0   74 strawberry apple belts 30      False strawberry apple belts 30      100\n",
            " 8.0   74 strawberry apple belts 30      False strawberry apple belts 30      98\n",
            "23.0   36 sativa blackberries and c      False sativa blackberries and c      98\n",
            "33.0   85 100mgthc : 100mgcbd : 100      False 100mgthc : 100mgcbd : 100      98\n",
            "21.0   85 lil doobiez tahoe diesel       False lil doobies tahoe diesel       98\n",
            "23.0   39 **medical only** ogeez! g      False **medical only** ogeez! g      98\n",
            "23.0   44 copia ogeez blackberries       False copia ogeez blackberries       98\n",
            " 8.0   77 blue raz rings 300 mg          False blue raz rings 300mg           98\n",
            " 8.0   78 watermelon rings 300mg         False watermelon rings 300mg         100\n",
            " 8.0   78 watermelon rings 300mg         False watermelon rings 300 mg        98\n",
            "error 0 order online  \n",
            "23.0   56 gummies 300mg   blackberr      False gummies 100mg   blackberr      98\n",
            "error in product loop\n",
            " 8.0   80 strawberry banana belts 1      False strawberry/banana belts 1      100\n",
            " 8.0   80 strawberry banana belts 1      False strawberry banana belts 1      100\n",
            "13.0   63 dark chocolate bar 100 mg      False dark chocolate bar 100mg       98\n",
            " 9.0   14 era life device grass          False era life device grass          100\n",
            " 8.0   81 watermelon belts 100mg         False watermelon belts 100mg         100\n",
            " 8.0   81 watermelon belts 100mg         False watermelon belts 1000mg        98\n",
            "26.0   61 pre roll   jay and silent      False pre roll   jay and silent      99\n",
            " 8.0   82 strawberry/banana belts 3      False strawberry banana belts 3      100\n",
            " 9.0   23 era life device grass          False era life device grass          100\n",
            " 9.0   34 era life device blaze          False era life device blaze          100\n",
            " 9.0   35 era life device onyx           False era life device onyx           100\n",
            "23.0   72 indica blackberries and c      False indica blackberries and c      98\n",
            " 9.0   36 era life device blaze          False era life device blaze          100\n",
            "23.0   74 indica blackberries and c      False indica blackberries and c      98\n",
            " 8.0   85 rainbow belts 100 mg           False rainbow belts 1000 mg          98\n",
            " 2.0   17 3.5g pre pack hybrid flow      False 3.5g pre pack hybrid flow      99\n",
            "23.0   76 **medical only** ogeez! g      False **medical only** ogeez! g      98\n",
            " 9.0   48 era life device onyx           False era life device onyx           100\n",
            "15.0   74 guicy banger #6 x skittle      False guicy banger #6 x skittle      98\n",
            " 8.0   91 blueberry belts 100 mg         False blueberry belts 100mg          98\n",
            " 8.0   91 blueberry belts 100 mg         False blueberry belts 100mg          98\n",
            "13.0   74 chocolate bars   1000mg v      False chocolate bars   100mg va      99\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "13.0   76 dark chocolate bar 1000mg      False dark chocolate bar 100mg       98\n",
            "13.0   80 milk chocolate bar 1000 m      False milk chocolate bar 1000mg      98\n",
            "21.0    3 super mega brownie s 225m      False super mega brownie s 225       98\n",
            "11.0    5 pink lemonade 100 mg           False *pink lemonade 1000 mg         98\n",
            "11.0    8 *pink lemonade 1000 mg         False pink lemonade 100 mg           98\n",
            "14.0   78 phoenix prickly pear hard      False phoenix prickly pear hard      99\n",
            "21.0   19 chronic health glycerin t      False chronic health glycerin t      98\n",
            "21.0   25 chronic health glycerin t      False chronic health glycerin t      98\n",
            "13.0   84 milk plain chocolate 1000      False milk plain chocolate 100m      98\n",
            "21.0   39 super mega brownie s 225       False super mega brownie s 225m      98\n",
            "13.0   87 100mg milk chocolate bar       False 1000mg milk chocolate bar      98\n",
            " 1.0   50 labs granddaddy purple po      False labs grandaddy purple pod      98\n",
            " 2.0   50 1g hybrid pre roll cherry      False 1g hybrid pre roll cherry      98\n",
            "16.0   23 elderberry 2:1 thc:cbn         False elderberry 2:1 thc/cbn         100\n",
            "21.0    9 flower hand long sleeve        False flower hand long sleeve        99\n",
            "13.0   92 cake batter 100mg              False cake batter 100mg              100\n",
            "21.0   18 flower hand long sleeve        False flower hand long sleeve        99\n",
            " 7.0   12 state forty eight x  coll      False state forty eight x  coll      99\n",
            " 7.0   12 state forty eight x  coll      False state forty eight x  coll      98\n",
            " 8.0   43 keef cola   orange kush 1      False keef cola   orange kush 1      98\n",
            "21.0   27 feel good sweatshirt   gr      False feel good sweatshirt   gr      98\n",
            "16.0   37 raspberry sativa enhanced      False raspberry sativa enhanced      99\n",
            "21.0   31 j'adore sweatshirt   whit      False j'adore sweatshirt   whit      98\n",
            "21.0   32 feel good sweatshirt   wh      False feel good sweatshirt   wh      98\n",
            "21.0   32 feel good sweatshirt   wh      False feel good sweatshirt   wh      98\n",
            "16.0   39 marionberry gummies 100mg      False marionberry gummies 100mg      100\n",
            "16.0   41 raspberry gummies 100mg        False raspberry gummies 100mg        100\n",
            "14.0   12 cola   purple passion sod      False cola   purple passion sod      98\n",
            " 7.0   42 state forty eight x  coll      False state forty eight x  coll      99\n",
            " 7.0   42 state forty eight x  coll      False state forty eight x  coll      99\n",
            " 7.0   42 state forty eight x  coll      False state forty eight x  coll      98\n",
            "21.0   44 j'adore sweatshirt   whit      False j'adore sweatshirt   whit      98\n",
            "21.0   45 feel good sweatshirt   wh      False feel good sweatshirt   wh      98\n",
            "14.0   26 cola   purple passion sod      False cola   purple passion sod      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "error 1 order online  \n",
            "error in product loop\n",
            " 4.0   40 sweet peach gummies 100mg      False sweet peach gummie s 100m      98\n",
            " 4.0   45 sweet peach gummie s 100m      False sweet peach gummies 100mg      98\n",
            "19.0   30 peppermint tincture 100mg      False peppermint tincture 1500m      98\n",
            "19.0   32 peppermint tincture 1500m      False peppermint tincture 100mg      98\n",
            "21.0   52 flower hand long sleeve        False flower hand long sleeve        99\n",
            " 2.0   98 3.5g pre pack hybrid flow      False 3.5g pre pack hybrid flow      99\n",
            "16.0   48 raspberry sativa enhanced      False raspberry sativa enhanced      99\n",
            "21.0   54 flower hand long sleeve        False flower hand long sleeve        99\n",
            "21.0   58 feel good t shirt   navy       False feel good t shirt   navy       98\n",
            "10.0    4 energy   16:1 cbd:thc          False energy   1:1 cbd:thc           98\n",
            "10.0   10 energy   1:1 cbd:thc           False energy   16:1 cbd:thc          98\n",
            " 8.0   88 keef cola   orange kush 1      False keef cola   orange kush 1      98\n",
            " 4.0    0 purely simple dissolvable      False purely simple dissolvable      99\n",
            "21.0   67 flower hand long sleeve        False flower hand long sleeve        99\n",
            "21.0   67 flower hand long sleeve        False flower hand long sleeve        99\n",
            "error 0 order online  \n",
            "error in product loop\n",
            "19.0   14 sweet kart blueberry pie       False sweet karts blueberry pie      98\n",
            "21.0   73 flower hand long sleeve        False flower hand long sleeve        99\n",
            "21.0   73 flower hand long sleeve        False flower hand long sleeve        99\n",
            " 4.0   38 purely simple dissolvable      False purely simple dissolvable      99\n",
            "22.0   67 tombstone lst blk xl           False tombstone lst blk 2xl          98\n",
            "22.0   67 tombstone lst blk xl           False tombstone lst blk 3xl          98\n",
            "21.0   78 feel good t shirt   white      False feel good t shirt   white      98\n",
            "21.0   98 flower hand long sleeve        False flower hand long sleeve        99\n",
            "21.0  100 feel good sweatshirt   gr      False feel good sweatshirt   gr      98\n",
            " 6.0    2 sugar cane                     False sugar cane                     100\n",
            " 6.0   12 night terror                   False night terror                   100\n",
            "16.0   84 gummies 5:1 elderberry 50      False gummies 5:1 elderberry 50      100\n",
            "16.0   84 gummies 5:1 elderberry 50      False gummies 2:1 elderberry 50      98\n",
            "22.0   83 highern chef niblet dark       False highern chef niblets dark      99\n",
            "16.0   89 pear gummies 1:1 cbg 100m      False pear gummies 1:1 cbg 100m      99\n",
            "19.0   79 og#18                          False og 18                          100\n",
            " 5.0    1 purple passion  h   100mg      False purple passion  h   10mg       98\n",
            " 5.0    2 purple passion  h   10mg       False purple passion  h   100mg      98\n",
            " 5.0    6 bubba kush root beer  i        False bubba kush root beer  i        98\n",
            " 6.0   38 terple                         False terple                         100\n",
            " 5.0   23 bubba kush root beer  i        False bubba kush root beer  i        98\n",
            "19.0   99 sweet kart apple pie 1000      False sweet karts apple pie 100      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            " 3.0   84 pax pod jack herer .5g         False pax pod jack herer 0.5g        98\n",
            "22.0   10 turtle power bar 100 mg        False turtle power bar 100mg         98\n",
            "22.0   15 power bar 100mg                False power bar 100mg                100\n",
            "22.0   19 turtle power bar 100mg         False turtle power bar 100 mg        98\n",
            "22.0   33 sand dollar 100mg 10 pack      False sand dollars 100mg 10 pac      98\n",
            "22.0   39 sand dollar 100mg              False sand dollar 100mg              100\n",
            "22.0   47 sand dollar 100mg              False sand dollar 100mg              100\n",
            "22.0   49 power bar 100mg                False power bar 100mg                100\n",
            "22.0   65 sand dollars 100mg 10 pac      False sand dollar 100mg 10 pack      98\n",
            "error 0 order online  \n",
            "error in product loop\n",
            " 3.0   26 500mg cbd tincture pepper      False 2500mg cbd tincture peppe      98\n",
            " 3.0   37 2500mg full spectrum tinc      False 500mg full spectrum tinct      99\n",
            " 3.0   41 2500mg cbd tincture peppe      False 500mg cbd tincture pepper      98\n",
            " 3.0   43 2500mg cbd tincture unfla      False 500mg cbd tincture unflav      98\n",
            " 3.0   44 2500mg full spectrum tinc      False 500mg full spectrum tinct      99\n",
            " 3.0   45 500mg full spectrum tinct      False 2500mg full spectrum tinc      99\n",
            " 3.0   51 500mg cbd tincture unflav      False 2500mg cbd tincture unfla      98\n",
            " 3.0   60 2500mg cbd tincture laven      False 500mg cbd tincture lavend      98\n",
            " 3.0   63 500mg cbd tincture lavend      False 2500mg cbd tincture laven      98\n",
            " 3.0   65 500mg full spectrum tinct      False 2500mg full spectrum tinc      99\n",
            " 0.0   98 squeeze watermelon 100 mg      False squeeze watermelon 100mg       98\n",
            " 0.0    2 3g pre roll pack vegas we      False +: 3g pre roll pack vegas      100\n",
            " 0.0   25 3g pre roll pack mimosa d      False +: 3g pre roll pack mimos      100\n",
            " 0.0   27 +: 3g pre roll pack mimos      False 3g pre roll pack mimosa d      100\n",
            " 0.0   42 +: 3g pre roll pack vegas      False 3g pre roll pack vegas we      100\n",
            " 0.0   50 3g pre roll pack face fue      False +: 3g pre roll pack face       100\n",
            " 0.0   54 +: 3g pre roll pack face       False 3g pre roll pack face fue      100\n",
            " 0.0   55 +: 3g pre roll pack sour       False 3g pre roll pack sour leo      100\n",
            " 0.0   65 3g pre roll pack sour leo      False +: 3g pre roll pack sour       100\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 92412 entries, 0 to 92411\n",
            "Data columns (total 23 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Dispensary        92412 non-null  object \n",
            " 1   total_products    92412 non-null  float64\n",
            " 2   Product_Url       92412 non-null  object \n",
            " 3   P_number          92412 non-null  int64  \n",
            " 4   Variant           92412 non-null  int64  \n",
            " 5   Product           92412 non-null  object \n",
            " 6   Product_size      44325 non-null  object \n",
            " 7   Manufacturer      92412 non-null  object \n",
            " 8   Category          92412 non-null  object \n",
            " 9   Listed_content    87052 non-null  object \n",
            " 10  THC%              87052 non-null  object \n",
            " 11  CBD%              87052 non-null  object \n",
            " 12  UOM               92412 non-null  object \n",
            " 13  Price             92412 non-null  object \n",
            " 14  Collected_at      92412 non-null  object \n",
            " 15  query_dirty       92412 non-null  object \n",
            " 16  query             92388 non-null  object \n",
            " 17  Manufacturer_chk  92403 non-null  object \n",
            " 18  prod_mast_nm      92412 non-null  object \n",
            " 19  THREAD            92412 non-null  float64\n",
            " 20  directory         92412 non-null  object \n",
            " 21  query_name        92412 non-null  object \n",
            " 22  Final_Name        45326 non-null  object \n",
            "dtypes: float64(2), int64(2), object(19)\n",
            "memory usage: 16.2+ MB\n",
            "None\n",
            "63497\n"
          ]
        }
      ],
      "source": [
        "# from numpy.core.fromnumeric import searchsorted\n",
        "# SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products.csv\")\n",
        "# SDF['prod_mast_nm']=\"NOT_MATCHED_YET\"\n",
        "# SDF=SDF[['Dispensary', 'total_products','Product_Url', 'P_number', 'Variant', 'Product',\n",
        "#        'Product_size', 'Manufacturer', 'Category', 'Listed_content', 'THC%',\n",
        "#        'CBD%', 'UOM', 'Price', 'Collected_at', 'query_dirty', 'query',\n",
        "#        'Manufacturer_chk', 'prod_mast_nm']]\n",
        "# MC=pd.DataFrame(SDF['Manufacturer'].value_counts())\n",
        "# MC.sort_values(['Manufacturer'],ascending=False,inplace=True)\n",
        "# print(len(set(SDF['query'])))\n",
        "# #### PREP\n",
        "# ##   Sort by highest vc mans\n",
        "# ##   spread evenly across threads\n",
        "# ##   threaded function will rebuild main df\n",
        "# MASTER_LIST=[]\n",
        "# THREADS=CORES\n",
        "# path=\"/content/drive/MyDrive/LEAFLY_Project/Data/THREAD_RESULTS/MAPPING\"\n",
        "# search=\"main_product_name_dispensary_side.csv\"\n",
        "\n",
        "# for m,man in enumerate(MC.index):\n",
        "#   SDF.loc[SDF['Manufacturer']==man,\"THREAD\"]=int(m%THREADS)\n",
        "\n",
        "# for i in range(THREADS):\n",
        "#   temp=[]\n",
        "#   tdf=SDF[SDF['THREAD']==i]\n",
        "#   tdf=tdf.copy()\n",
        "#   tdf['directory']=path\n",
        "#   tdf['query_name']=search\n",
        "#   tdf.reset_index(inplace=True)\n",
        "#   tdf.drop(['index'],axis=1,inplace=True)\n",
        "#   MASTER_LIST.append(tdf)\n",
        "\n",
        "\n",
        "# def make_master_product_names(DF):\n",
        "#   thread=DF.at[0,'THREAD']\n",
        "#   MANS=list(set(DF['Manufacturer']))\n",
        "#   #print(len(MANS))\n",
        "#   for man in MANS:\n",
        "#     tdf=DF[DF['Manufacturer']==man]\n",
        "#     man_prod_list=list(set(tdf['query']))\n",
        "\n",
        "    \n",
        "#     for p,prod in enumerate(man_prod_list):\n",
        "#       try:\n",
        "#         if p>100:\n",
        "#           break\n",
        "#         try:\n",
        "#           ops=process.extract(prod,man_prod_list)\n",
        "#         except:\n",
        "#           print(f\"error {p} {product} \")\n",
        "        \n",
        "#         high_score=0\n",
        "#         MATCHED=False\n",
        "#         possibles=[]\n",
        "#         for o,op in enumerate(ops):\n",
        "    \n",
        "#           if op[1]>high_score:\n",
        "#             high_score=op[1]\n",
        "#           if op[1]>=99:\n",
        "#             MATCHED=True\n",
        "#           if op[1]>=98 and op[0]!=prod:\n",
        "#             possibles.append(op)\n",
        "        \n",
        "    \n",
        "#         if len(possibles)>=1:\n",
        "#           v1=prod\n",
        "#           test=DF[DF['Manufacturer']==man]\n",
        "#           pc=pd.DataFrame(test['query'].value_counts())\n",
        "#           max=0\n",
        "#           v1_count=pc.at[v1,'query']\n",
        "#           for it, item in enumerate(possibles):\n",
        "#             try:\n",
        "#               print(f\"{thread:4} {p:4} {prod[:25]:30} {prod==item[0]} {item[0][:25]:30} {item[1]}\")\n",
        "#             except:\n",
        "#               print(\"print error\")\n",
        "#           #DF.loc[DF['query']==v1,'Final_Name']=v1\n",
        "          \n",
        "#         else:\n",
        "#           DF.loc[DF['query']==prod,'Final_Name']=prod\n",
        "\n",
        "#       except:\n",
        "#         print(\"error in product loop\",product)    \n",
        "          \n",
        "\n",
        "          \n",
        "\n",
        "#       # if thread==0 and len(possibles)>1:\n",
        "#       #   print(f\"On MAN:{man:35} of {len(MANS):4} for product {prod:45} {p:4} of {len(man_prod_list):4} there are {len(possibles):4} possibles\")\n",
        "\n",
        "#   return DF\n",
        "\n",
        "# def make_master_product_names_THREADED(MASTER_LIST):\n",
        "\n",
        "#   threads=len(MASTER_LIST)\n",
        "\n",
        "#   FDF=pd.DataFrame()\n",
        "#   FMMDF=pd.DataFrame()\n",
        "  \n",
        "#   with concurrent.futures.ProcessPoolExecutor(max_workers=threads) as executor:\n",
        "#     try:\n",
        "#         for r,results in enumerate(executor.map(make_master_product_names,MASTER_LIST)):\n",
        "#           FDF=FDF.append(results,ignore_index=True)\n",
        "        \n",
        "#         # path=FDF.at[0,'directory']\n",
        "#         # file_name=FDF.at[0,'query_name']\n",
        "#         # file_date_stamp=dt.datetime.now()\n",
        "#         # file_date_stamp=file_date_stamp.strftime(\"%m_%d_%Y_%H_%M_\")\n",
        "#         # FDF.to_csv(join(path,f\"_{file_name}\"),index=False)\n",
        "#         # FDF.to_csv(join(path,f\"_{file_date_stamp}_{file_name}\"),index=False)\n",
        "#         print(FDF.info())\n",
        "#         print(len(set(FDF['Final_Name'])))\n",
        "#     except:\n",
        "#         print(\"OOPS\")\n",
        "\n",
        "#   return FDF\n",
        "\n",
        "# #   man_products=SDF.loc[SDF['Manufacturer']==man,'query'].to_list()\n",
        "# #   for product in man_products:\n",
        "# #     ops=process.extract(product,man_products)\n",
        "# #     print(m,len(MANS),ops)\n",
        "# FDF=make_master_product_names_THREADED(MASTER_LIST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hJebALBKTc9"
      },
      "outputs": [],
      "source": [
        "# SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_mans.csv\")\n",
        "# MAN_PROD=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/MASTER_PRODUCT_LSIT_renamed_mans.csv\")\n",
        "\n",
        "# SDF.loc[SDF['Manufacturer'].isna(),'Manufacturer']=\"TBD9999999999999999999999999999888888888888888888888888888888\"\n",
        "# SDF.loc[SDF['Manufacturer']==\"-\",'Manufacturer']=\"TBD99999999999999999999999999999999999999999999999999\"\n",
        "# #list of manufacturers\n",
        "# disp_mans=list(set(SDF['Manufacturer']))\n",
        "# mans=list(set(MAN_PROD['Manufacturer']))\n",
        "\n",
        "\n",
        "# #DF lookup table for competing names\n",
        "# VC=pd.DataFrame(SDF['Manufacturer'].value_counts())\n",
        "\n",
        "# #depending on cpu use, Process pool or Thread pool will be used for asynchronous processing\n",
        "# #keep in mind that a=b in one thread, b=a in another or in a different search.  resolve this\n",
        "# # by picking the one with more products as the master name.  will require manual review of changes\n",
        "# # but, can autmate the process with screen input once out of the step\n",
        "\n",
        "\n",
        "# #Prepair data for asynchrounous processing\n",
        "# THREADS=CORES\n",
        "\n",
        "# query  = disp_mans.copy()\n",
        "# search = mans.copy()\n",
        "\n",
        "# QUERY  = pd.DataFrame(query ,columns=['Manufacturer'])\n",
        "# SEARCH = pd.DataFrame(search,columns=['Manufacturer'])\n",
        "\n",
        "# #configure \n",
        "# QUERY['THREAD']=QUERY.index%THREADS\n",
        "# MASTER_LIST=[]\n",
        "# for i in range(THREADS):\n",
        "#   temp  = []\n",
        "#   tdf   = QUERY[QUERY['THREAD']==i]\n",
        "#   #send copies not pointers to original\n",
        "#   tdf   = tdf.copy()\n",
        "#   #easier to reference rows\n",
        "#   tdf.reset_index(inplace=True)\n",
        "#   tdf.drop(['index'],axis=1,inplace=True)\n",
        "#   tdf['query_column'] = 'Manufacturer'\n",
        "#   tdf['query_name']=\"product_manufacturer_vs_vendor_manufacturer_.csv\"\n",
        "#   tdf['directory'] = \"/content/drive/MyDrive/LEAFLY_Project/Data/THREAD_RESULTS/MAPPING\"\n",
        "#   tdf['Multiple_Possible_Names']=False\n",
        "#   tdf['MASTER_MAN_NAME']=tdf['Manufacturer']\n",
        "#   tdf['algo_step']=1\n",
        "#   SEARCH = SEARCH.copy()\n",
        "#   SEARCH['search_column']='Manufacturer'\n",
        "#   temp.append(tdf)\n",
        " \n",
        "#   temp.append(SEARCH)\n",
        "#   VC=VC.copy()\n",
        "#   temp.append(VC)\n",
        "#   MASTER_LIST.append(temp)\n",
        "\n",
        "\n",
        "# FDF=process_for_match_THREADED(MASTER_LIST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3UPF2aAzpqI"
      },
      "outputs": [],
      "source": [
        "# def pull_uoms(product,p,tdf,products=\"False\"):\n",
        "\n",
        "#   \"\"\"\n",
        "#   refactor these using \\s{0,2} to reduce the number of searches\n",
        "#   order them to overwrite a = b, b!=a\n",
        "#   update tdf as found to ensure explicit recording\n",
        "\n",
        "#   buil a coonversaion formula / function to convert g to mg for consistent labeling\n",
        "#   \"\"\"\n",
        "  \n",
        "#   units= {'ratio':  {'ratio':r'([^:]\\d{1,4}\\s{0,2}:\\s{0,2}\\d{1,4}[^:])','_ratio':r'(\\d{1,4}\\s:\\s\\d{1,4})',\n",
        "#                     'ratioo':r'(\\d{1,4}:\\d{1,4}:\\d{1,4})','_ratioo':r'(\\d{1,4}\\s:\\s\\d{1,4}:\\d{1,4})',\n",
        "#                     'ratiooo':r'(\\d{1,4}:\\d{1,4}:\\d{1,4}:\\d{1,4})','_ratiooo':r'(\\d{1,4}\\s:\\s\\d{1,4}:\\d{1,4}:\\d{1,4})'},\n",
        "          \n",
        "#           'thc_cbd':{'thc': r'(\\d{1,3}mgthc/\\d{1,3}mgcbd)',      'thc_': r'(\\s\\d{1,5}mgthc/\\d{1,5}mg\\scbd)',\n",
        "#                    '_thc': r'(\\s\\d{1,5}mg\\sthc/\\d{1,5}mgcbd)','_thc_': r'(\\s\\d{1,5}mg\\sthc/\\d{1,5}mg\\scbd)',\n",
        "#                    '_thcwt':r'(\\d{1,4}mgthc\\s{0,1}:\\s{0,1}\\d{1,4}mgcbg)'},\n",
        "          \n",
        "#           'mg':     {'mg' :r'(\\d{1,4}mg)','_mg':r'(\\d{1,4}\\smg)'},\n",
        "          \n",
        "#           'g':      {'g'  :r'(^\\d\\s\\d{1,4}g)' ,'_g' :r'(^\\d\\s\\d{1,4}\\sg)',\n",
        "#                     'decg'  :r'(^\\d\\s.\\d{1}g)' ,'_decg' :r'(^\\d\\s.\\d{1,4}\\sg)',\n",
        "#                     'gdecg'  :r'(\\d{1}.\\d{1,4}g)' ,'_gdecg' :r'(\\d{1,4}.\\d{1,4}\\sg)'},\n",
        "          \n",
        "#           'oz':     {'oz' :r'(\\d{1,4}oz)','_oz':r'(\\d{1,4}\\soz)',\n",
        "#                     'frc_':r'(\\d{1,4}/\\d{1,4}\\soz)', 'frcopslash':r'(\\d{1,4}\\\\\\d{1,4})',\n",
        "#                     'frc' :r'(\\d{1,3}/\\d{1,3}oz)'},\n",
        "          \n",
        "#           'pk':     {'pk' :r'(\\d{1,4}pk)','_pk':r'(\\d{1,4}\\spk)',\n",
        "#                     'pack' :r'(\\d{1,4}pack)','_pack':r'(\\d{1,4}\\spack)',\n",
        "#                     'ct':r'(\\d{1-4}ct)','_ct':r'(\\d{1-4}\\spack)'},\n",
        "#           'pk_cont':{'count_x_measureg':'(\\d{1,5}\\sx\\s\\d{1,5}g)',\n",
        "#                      'count_x_measuremg':'(\\d{1,5}\\sx\\s\\d{1,5}mg)'},\n",
        "          \n",
        "          \n",
        "        \n",
        "          \n",
        "#           'strain' :{'i':r'(\\si\\s)','ih':'\\si/h\\s','sh':r'(\\ss/h\\s)','hs':r'(\\sh/s\\s)','hi':r'(\\sh/i\\s)','h':r'(\\sh\\s)'},\n",
        "#   }\n",
        "  \n",
        "#   result=False\n",
        "#   for k,v in units.items():\n",
        "#     res=\"0\"\n",
        "#     for label,regex in v.items():\n",
        "#       #print(f\"look for this unit of measure {label} with this regex {regex}\")\n",
        "#       result = re.findall(regex, product)\n",
        "  \n",
        "#       if result:\n",
        "#         for res in result:\n",
        "#           tdf.at[0,k]=res.replace(k,'')\n",
        "#           if p%500==0:\n",
        "#             print(f\"Product: {p:5} Unit: {k:6} {label:6} {res.replace(k,''):10} {product:50}\")\n",
        "\n",
        "#   return(tdf)\n",
        "\n",
        "\n",
        "# def parse_products(LIST_o):\n",
        "\n",
        "#   DFO=LIST_o[0]\n",
        "#   #print(DFO.shape)\n",
        "#   RDF=pd.DataFrame()\n",
        "\n",
        "#   products=list(DFO['Product_Url'])\n",
        "\n",
        "\n",
        "#   for p,product in enumerate(products):\n",
        "    \n",
        "#     tdf=DFO[DFO['Product_Url']==product]\n",
        "#     tdf=tdf.copy()\n",
        "#     tdf=tdf.reset_index()\n",
        "#     tdf=tdf.drop(['index'],axis=1)\n",
        "#     if len(tdf)<1:\n",
        "#       print(\"ohhhhhhhhhhhhhhhhhh\")\n",
        "#     #print(tdf.shape)\n",
        "#     #DFO=pull_uoms(product,p,SDF)\n",
        "#     else:\n",
        "#       query=tdf.at[0,'query']\n",
        "#       pull_uoms(query,p,tdf)\n",
        "#       RDF=RDF.append(tdf,ignore_index=True)\n",
        "\n",
        "#   return(RDF)\n",
        "\n",
        "\n",
        "# def MASTER_LIST_parse_products(THREADS):\n",
        "\n",
        "#   SDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products.csv\")\n",
        "#   SDF=SDF[['Dispensary', 'Name_Tag', 'total_products','Product_size', 'Manufacturer', 'Category', 'Listed_content', 'THC%',\n",
        "#         'CBD%', 'UOM', 'Price', 'query','Manufacturer_chk','Product_Url']]\n",
        "#   print(SDF.shape)       \n",
        "#   print(SDF.columns)\n",
        "\n",
        "#   SDF=SDF.drop_duplicates(subset=\"Product_Url\",keep='first')\n",
        "#   SDF=SDF[~SDF['query'].isna()]\n",
        "#   SDF = SDF.dropna(subset=['query'])\n",
        "#   SDF=SDF.reset_index()\n",
        "#   SDF=SDF.drop(['index'],axis=1)\n",
        "\n",
        "#   print(SDF.shape)\n",
        "  \n",
        "#   MASTER_LIST=[]\n",
        "#   SDF['THREAD']=SDF.index%THREADS\n",
        "#   for i in range(THREADS):\n",
        "#     temp=[]\n",
        "#     tdf=SDF[SDF['THREAD']==i]\n",
        "#     print(tdf.shape)\n",
        "#     tdf=tdf.copy()\n",
        "#     tdf.reset_index(inplace=True)\n",
        "#     tdf.drop(['index'],axis=1,inplace=True)\n",
        "#     temp.append(tdf)\n",
        "#     MASTER_LIST.append(temp)\n",
        "    \n",
        "#   return(MASTER_LIST)\n",
        "\n",
        "# def parse_products_THREADED(MASTER_LIST):\n",
        "#   threads=len(MASTER_LIST)\n",
        "#   FDF=pd.DataFrame()\n",
        "#   FMMDF=pd.DataFrame()\n",
        "#   with concurrent.futures.ProcessPoolExecutor(max_workers=threads) as executor:\n",
        "#     try:\n",
        "#         for r,results in enumerate(executor.map(parse_products,MASTER_LIST)):\n",
        "#           FDF=FDF.append(results,ignore_index=True)\n",
        "#         print(\"TESTING\")\n",
        "#         # path=FDF.at[0,'directory']\n",
        "#         # file_name=FDF.at[0,'query_name']\n",
        "#         # file_date_stamp=dt.datetime.now()\n",
        "#         # file_date_stamp=file_date_stamp.strftime(\"%m_%d_%Y_%H_%M_\")\n",
        "#         # FDF.to_csv(join(path,f\"_{file_name}\"),index=False)\n",
        "#         # FDF.to_csv(join(path,f\"_{file_date_stamp}_{file_name}\"),index=False)\n",
        "#         print(FDF.info())\n",
        "\n",
        "#     except:\n",
        "#         print(\"OOPS\")\n",
        "#   return(FDF)\n",
        "\n",
        "\n",
        "# THREADS=CORES\n",
        "# MASTER_LIST=MASTER_LIST_parse_products(THREADS)\n",
        "# FDF=parse_products_THREADED(MASTER_LIST)\n",
        "\n",
        "# FDF.to_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_now_parsed.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FDF=pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Inputs/DISP_PRODUCT_LSIT_renamed_products_now_parsed_and_overwritten_part_1_of_2_.csv\")\n",
        "# #FDF =pd.read_csv(\"/content/drive/MyDrive/LEAFLY_Project/Data/Run_Results/9Stone/_AZ_Market_Data_.csv\")\n",
        "# #regex=r\"((((\\.){0,1}\\d{1,4}\\.{0,1}\\d{0,2}\\s{0,1})(mg|g|oz|:|thc|cbd|cbn|pk))\\s{0,1}\\d{0,4}(mg|g\\s|oz|:|thc|cbd|cbn))\"\n",
        "# #regex=r\"((\\.){0,1}\\d{1,4}\\.{0,1}\\d{0,2})\"\n",
        "# \"\"\"\n",
        "# KEEP: \n",
        "\n",
        "# [ratio only regex]: r\"(\\d{1,5}\\s{0,1}(:\\s{0,1}\\d{1,3}){1,5})\"\n",
        "# [ratio : / weight content (but picks up fractions too)] : r\"((\\d{1,5}\\s{0,1}((mg|g\\s|thc|cbd|cbg|cbn){0,2}\\s{0,1}){1,2})((\\/|:)\\s{0,1}\\d{1,5}\\s{0,1}((mg|g\\s|thc|cbd|cbg|cbn){0,2}\\s{0,1}){1,2}){1,4})\"\n",
        "# [pack : g x count, or count]:r\"(((\\d{1,4}\\s{0,1}(pk|pack))|(\\s\\d{0,3}\\s{0,1}.{0,1}\\d{0,2}(g\\s|mg\\s|oz\\s))\\s{0,1}x\\s{0,1}\\d{1,4})|((\\s\\d{0,3}\\s{0,1}.{0,1}\\d{0,2}x\\s{0,1}\\d{1,4}(g\\s|mg\\s|oz\\s))\\s{0,1}))\"\n",
        "# ==      FDF.at[i,\"TAG\"]+=f\"+packsize:<{res[0].replace(' ','').replace('pack','pk')}>\"\n",
        "#         FDF.at[i,'BASE_NAME']=product.replace(\"[\",\"\").replace(\"]\",\"\")\n",
        "\n",
        "# \"\"\"\n",
        "# FDF['BASE_NAME']=FDF['product']\n",
        "# #Just ratio tags no content lables\n",
        "# regex=r\"(\\s{0,1}\\d{0,4}\\s{0,1}\\d{1,4}\\s{0,1}\\/\\s{0,1}\\d{1,4}\\s{0,1}(g\\s|oz\\s|mg\\s|\\s))\"\n",
        "# FDF['TAG']=\"\"\n",
        "# for i in FDF.index:\n",
        "#   product=FDF.at[i,'product']\n",
        "#   # result = re.search(regex, product)\n",
        "#   # if result:\n",
        "#   #   print(result)\n",
        "#   search=re.search(regex,product)\n",
        "#   if search:\n",
        "#     print(search[0],product)\n",
        "#   # result = re.findall(regex, product)\n",
        "#   # original = product\n",
        "#   # if result:\n",
        "#   #   for res in result:\n",
        "#   #     #new=num2words(res[0])\n",
        "#   #     product=product.replace(res[0],'',1)\n",
        "#   #     FDF.at[i,\"TAG\"]+=f\"+packsize:<{res[0].replace(' ','').replace('pack','pk')}>\"\n",
        "#   #     FDF.at[i,'BASE_NAME']=product.replace(\"[\",\"\").replace(\"]\",\"\")\n",
        "#   #     # product=product+\" \"+new\n",
        "#   #     print(f\"{res[0]:20} >><<< {original:60}======{product:60}\")\n",
        "\n",
        "# #FDF.head(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K24PC79vHXx2",
        "outputId": "c9b8f3d3-21ba-4aed-b7a6-6da37e396baa"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1/4  1 1/4 classic rolling papers \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DISP_2_MAN_MAP.ipynb",
      "provenance": [],
      "mount_file_id": "1ikI0Xb8qgY12aVT7dg1ajyvauGIqbk60",
      "authorship_tag": "ABX9TyP77YbH0PLHTn7hIdJ13mRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}